{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e267eebb-1c86-4e6f-af5e-e75fd97be8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/shugo/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/notebooks', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python37.zip', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload', '', '/Users/shugo/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages', '/Users/shugo/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/IPython/extensions', '/Users/shugo/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('../modules/')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_origin = pd.read_csv('../input/train.csv')\n",
    "test_origin = pd.read_csv('../input/test.csv')\n",
    "\n",
    "df_train = train_origin.copy()\n",
    "df_test = test_origin.copy()\n",
    "\n",
    "df_sample_sub = pd.read_csv('../input/sample_submit.csv', header=None)\n",
    "df_sample_sub.columns = ['index', 'genre']\n",
    "df_genre_labels = pd.read_csv('../input/genre_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377bfdc3-9fbd-47f8-bc4e-33f811832b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 11\n",
    "\n",
    "# testのジャンルを-100として結合\n",
    "def merge_train_test(df_train, df_test):\n",
    "    if 'genre' not in df_test.columns.tolist():\n",
    "        df_test['genre'] = -100\n",
    "    res = pd.concat([df_train, df_test])\n",
    "    res.reset_index(inplace=True, drop = True)\n",
    "    return res\n",
    "\n",
    "def split_train_test(df):\n",
    "    df_train = df[df['genre'] != -100]\n",
    "    df_test = df[df['genre'] == -100]\n",
    "    df_train.reset_index(inplace=True, drop=True)\n",
    "    df_test.reset_index(inplace=True, drop =True)\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore', pd.core.common.SettingWithCopyWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "\n",
    "N_CLASSES = 11\n",
    "\n",
    "\n",
    "INPUT = Path(\"../input\")\n",
    "df_train = pd.read_csv(INPUT / \"train.csv\")\n",
    "df_test = pd.read_csv(INPUT / \"test.csv\")\n",
    "df_sample_sub = pd.read_csv(INPUT / \"sample_submit.csv\", header=None)\n",
    "df_sample_sub.columns = [\"index\", \"genre\"]\n",
    "df_genre_labels = pd.read_csv(INPUT / \"genre_labels.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# parameters\n",
    "\n",
    "# def lgb_metric(preds, data):  \n",
    "#     pred_labels = preds.reshape(N_CLASSES, -1).argmax(axis=0)\n",
    "#     score = f1_score(data.get_label(), pred_labels, average=\"macro\")\n",
    "#     return \"macro_f1\", score, True\n",
    "\n",
    "learning_rate = 0.01\n",
    "lgb_params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": N_CLASSES,\n",
    "    #\"metric\": \"None\",\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"num_leaves\": 3,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "    #\"colsample_bytree\": 1.0,\n",
    "    #\"feature_fraction\": 1.0,\n",
    "    #\"bagging_freq\": 0,\n",
    "    #\"bagging_fraction\": 1.0,\n",
    "    \"verbosity\": 0,\n",
    "    \"seed\": 42,\n",
    "    \"force_col_wise\":True\n",
    "}\n",
    "\n",
    "knn_n_neighbors = 6\n",
    "\n",
    "\n",
    "# parameters - knn feature weights\n",
    "\n",
    "knn_features = [\n",
    "   'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "   'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "   'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "   'region_S', 'region_T', 'region_unknown',\n",
    "   'standardscaled_popularity', 'standardscaled_duration_ms',\n",
    "   'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "   'standardscaled_danceability', 'standardscaled_loudness',\n",
    "   'standardscaled_energy', 'standardscaled_liveness',\n",
    "   'standardscaled_speechiness', 'standardscaled_instrumentalness',\n",
    "   'standardscaled_log_tempo', 'standardscaled_num_nans'\n",
    "]\n",
    "\n",
    "dict_feature_weights = {}\n",
    "\n",
    "for col in [\n",
    "    'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "    'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "    'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "    'region_S', 'region_T', 'region_unknown'\n",
    "]:\n",
    "    dict_feature_weights[col] = 100.0\n",
    "\n",
    "for col in [\n",
    "    'standardscaled_duration_ms',\n",
    "    'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "    'standardscaled_danceability', 'standardscaled_loudness',\n",
    "    'standardscaled_energy', 'standardscaled_liveness',\n",
    "    'standardscaled_speechiness', 'standardscaled_instrumentalness'\n",
    "]:\n",
    "    dict_feature_weights[col] = 1.0\n",
    "\n",
    "dict_feature_weights[\"standardscaled_popularity\"] = 8.0\n",
    "dict_feature_weights[\"standardscaled_log_tempo\"] = 0.001\n",
    "dict_feature_weights[\"standardscaled_num_nans\"] = 100.0\n",
    "\n",
    "knn_feature_weights = np.array([dict_feature_weights[col] for col in knn_features])\n",
    "\n",
    "def merge_train_test(df_train, df_test):\n",
    "\n",
    "    if \"genre\" not in df_test.columns.tolist():\n",
    "        df_test[\"genre\"] = -100\n",
    "    res = pd.concat([df_train, df_test])\n",
    "    res.reset_index(inplace=True, drop=True)\n",
    "    return res\n",
    "\n",
    "def split_train_test(df):\n",
    "    df_train = df[df[\"genre\"] != -100]\n",
    "    df_test = df[df[\"genre\"] == -100]\n",
    "    df_train.reset_index(inplace=True, drop=True)\n",
    "    df_test.reset_index(inplace=True, drop=True)\n",
    "    return df_train, df_test\n",
    "\n",
    "df_main = merge_train_test(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265e8476-e0a1-4974-8cb5-cb20e2bb7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.7406\tvalid_1's multi_logloss: 0.895948\n",
      "[600]\ttraining's multi_logloss: 0.66018\tvalid_1's multi_logloss: 0.868034\n",
      "[900]\ttraining's multi_logloss: 0.607226\tvalid_1's multi_logloss: 0.867231\n",
      "[1200]\ttraining's multi_logloss: 0.564282\tvalid_1's multi_logloss: 0.869029\n",
      "Early stopping, best iteration is:\n",
      "[960]\ttraining's multi_logloss: 0.597944\tvalid_1's multi_logloss: 0.866644\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.741499\tvalid_1's multi_logloss: 0.806882\n",
      "[600]\ttraining's multi_logloss: 0.658472\tvalid_1's multi_logloss: 0.786777\n",
      "[900]\ttraining's multi_logloss: 0.601987\tvalid_1's multi_logloss: 0.779658\n",
      "[1200]\ttraining's multi_logloss: 0.557427\tvalid_1's multi_logloss: 0.780822\n",
      "Early stopping, best iteration is:\n",
      "[1014]\ttraining's multi_logloss: 0.584102\tvalid_1's multi_logloss: 0.779152\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.741642\tvalid_1's multi_logloss: 0.821737\n",
      "[600]\ttraining's multi_logloss: 0.659054\tvalid_1's multi_logloss: 0.806695\n",
      "[900]\ttraining's multi_logloss: 0.603685\tvalid_1's multi_logloss: 0.808143\n",
      "Early stopping, best iteration is:\n",
      "[696]\ttraining's multi_logloss: 0.639719\tvalid_1's multi_logloss: 0.805379\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.753623\tvalid_1's multi_logloss: 0.769607\n",
      "[600]\ttraining's multi_logloss: 0.671486\tvalid_1's multi_logloss: 0.746686\n",
      "[900]\ttraining's multi_logloss: 0.616351\tvalid_1's multi_logloss: 0.74522\n",
      "[1200]\ttraining's multi_logloss: 0.571932\tvalid_1's multi_logloss: 0.742451\n",
      "[1500]\ttraining's multi_logloss: 0.535041\tvalid_1's multi_logloss: 0.739592\n",
      "[1800]\ttraining's multi_logloss: 0.501591\tvalid_1's multi_logloss: 0.740578\n",
      "Early stopping, best iteration is:\n",
      "[1604]\ttraining's multi_logloss: 0.522972\tvalid_1's multi_logloss: 0.739017\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.75413\tvalid_1's multi_logloss: 0.802151\n",
      "[600]\ttraining's multi_logloss: 0.671884\tvalid_1's multi_logloss: 0.77227\n",
      "[900]\ttraining's multi_logloss: 0.61836\tvalid_1's multi_logloss: 0.76553\n",
      "[1200]\ttraining's multi_logloss: 0.575461\tvalid_1's multi_logloss: 0.762396\n",
      "Early stopping, best iteration is:\n",
      "[1178]\ttraining's multi_logloss: 0.578284\tvalid_1's multi_logloss: 0.761729\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.749616\tvalid_1's multi_logloss: 0.836748\n",
      "[600]\ttraining's multi_logloss: 0.665199\tvalid_1's multi_logloss: 0.821377\n",
      "Early stopping, best iteration is:\n",
      "[548]\ttraining's multi_logloss: 0.676812\tvalid_1's multi_logloss: 0.821049\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.759584\tvalid_1's multi_logloss: 0.732254\n",
      "[600]\ttraining's multi_logloss: 0.677236\tvalid_1's multi_logloss: 0.69802\n",
      "[900]\ttraining's multi_logloss: 0.622911\tvalid_1's multi_logloss: 0.696086\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttraining's multi_logloss: 0.648701\tvalid_1's multi_logloss: 0.694938\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.735973\tvalid_1's multi_logloss: 0.867829\n",
      "[600]\ttraining's multi_logloss: 0.652995\tvalid_1's multi_logloss: 0.861707\n",
      "Early stopping, best iteration is:\n",
      "[440]\ttraining's multi_logloss: 0.690969\tvalid_1's multi_logloss: 0.859752\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.745535\tvalid_1's multi_logloss: 0.909454\n",
      "[600]\ttraining's multi_logloss: 0.661881\tvalid_1's multi_logloss: 0.8861\n",
      "[900]\ttraining's multi_logloss: 0.605747\tvalid_1's multi_logloss: 0.882968\n",
      "[1200]\ttraining's multi_logloss: 0.56263\tvalid_1's multi_logloss: 0.881523\n",
      "[1500]\ttraining's multi_logloss: 0.525873\tvalid_1's multi_logloss: 0.880732\n",
      "Early stopping, best iteration is:\n",
      "[1478]\ttraining's multi_logloss: 0.528405\tvalid_1's multi_logloss: 0.88013\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.740312\tvalid_1's multi_logloss: 0.908284\n",
      "[600]\ttraining's multi_logloss: 0.658204\tvalid_1's multi_logloss: 0.873685\n",
      "[900]\ttraining's multi_logloss: 0.603882\tvalid_1's multi_logloss: 0.864284\n",
      "[1200]\ttraining's multi_logloss: 0.560103\tvalid_1's multi_logloss: 0.860318\n",
      "[1500]\ttraining's multi_logloss: 0.522256\tvalid_1's multi_logloss: 0.861784\n",
      "Early stopping, best iteration is:\n",
      "[1230]\ttraining's multi_logloss: 0.556078\tvalid_1's multi_logloss: 0.859852\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.753867\tvalid_1's multi_logloss: 0.820329\n",
      "[600]\ttraining's multi_logloss: 0.671336\tvalid_1's multi_logloss: 0.801882\n",
      "Early stopping, best iteration is:\n",
      "[483]\ttraining's multi_logloss: 0.697557\tvalid_1's multi_logloss: 0.800032\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.739471\tvalid_1's multi_logloss: 0.80899\n",
      "[600]\ttraining's multi_logloss: 0.656238\tvalid_1's multi_logloss: 0.787828\n",
      "[900]\ttraining's multi_logloss: 0.601029\tvalid_1's multi_logloss: 0.785497\n",
      "Early stopping, best iteration is:\n",
      "[853]\ttraining's multi_logloss: 0.60882\tvalid_1's multi_logloss: 0.785251\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.736581\tvalid_1's multi_logloss: 0.901997\n",
      "[600]\ttraining's multi_logloss: 0.652608\tvalid_1's multi_logloss: 0.871573\n",
      "[900]\ttraining's multi_logloss: 0.598132\tvalid_1's multi_logloss: 0.872995\n",
      "Early stopping, best iteration is:\n",
      "[606]\ttraining's multi_logloss: 0.651355\tvalid_1's multi_logloss: 0.871401\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.741457\tvalid_1's multi_logloss: 0.86744\n",
      "[600]\ttraining's multi_logloss: 0.660158\tvalid_1's multi_logloss: 0.84463\n",
      "Early stopping, best iteration is:\n",
      "[588]\ttraining's multi_logloss: 0.662695\tvalid_1's multi_logloss: 0.844214\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.750702\tvalid_1's multi_logloss: 0.819545\n",
      "[600]\ttraining's multi_logloss: 0.667659\tvalid_1's multi_logloss: 0.807296\n",
      "Early stopping, best iteration is:\n",
      "[541]\ttraining's multi_logloss: 0.6804\tvalid_1's multi_logloss: 0.805726\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.66155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71        32\n",
      "           1       0.59      0.41      0.48       205\n",
      "           2       0.70      0.58      0.64       191\n",
      "           3       0.80      0.76      0.78       362\n",
      "           4       0.71      0.60      0.65        45\n",
      "           5       0.61      0.50      0.55       126\n",
      "           6       0.56      0.36      0.44        50\n",
      "           7       0.66      0.63      0.64       334\n",
      "           8       0.72      0.79      0.76      1305\n",
      "           9       0.86      0.81      0.83        59\n",
      "          10       0.78      0.81      0.79      1337\n",
      "\n",
      "    accuracy                           0.74      4046\n",
      "   macro avg       0.71      0.63      0.66      4046\n",
      "weighted avg       0.73      0.74      0.73      4046\n",
      "\n",
      "437 rows were filled. (confidence>0.95)\n",
      "filled test labels: [  5   0   0  99   0   0   0   0  13  18 302]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.665889\tvalid_1's multi_logloss: 0.855908\n",
      "[600]\ttraining's multi_logloss: 0.590606\tvalid_1's multi_logloss: 0.858279\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttraining's multi_logloss: 0.628722\tvalid_1's multi_logloss: 0.852101\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.673292\tvalid_1's multi_logloss: 0.722087\n",
      "[600]\ttraining's multi_logloss: 0.598643\tvalid_1's multi_logloss: 0.698249\n",
      "[900]\ttraining's multi_logloss: 0.549363\tvalid_1's multi_logloss: 0.695431\n",
      "Early stopping, best iteration is:\n",
      "[885]\ttraining's multi_logloss: 0.5516\tvalid_1's multi_logloss: 0.694935\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.672328\tvalid_1's multi_logloss: 0.7299\n",
      "[600]\ttraining's multi_logloss: 0.595945\tvalid_1's multi_logloss: 0.719523\n",
      "Early stopping, best iteration is:\n",
      "[479]\ttraining's multi_logloss: 0.621327\tvalid_1's multi_logloss: 0.717222\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.674354\tvalid_1's multi_logloss: 0.716267\n",
      "[600]\ttraining's multi_logloss: 0.597177\tvalid_1's multi_logloss: 0.6886\n",
      "[900]\ttraining's multi_logloss: 0.548098\tvalid_1's multi_logloss: 0.678063\n",
      "[1200]\ttraining's multi_logloss: 0.508533\tvalid_1's multi_logloss: 0.67441\n",
      "[1500]\ttraining's multi_logloss: 0.474684\tvalid_1's multi_logloss: 0.6739\n",
      "[1800]\ttraining's multi_logloss: 0.444855\tvalid_1's multi_logloss: 0.673858\n",
      "Early stopping, best iteration is:\n",
      "[1590]\ttraining's multi_logloss: 0.465461\tvalid_1's multi_logloss: 0.673222\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.68388\tvalid_1's multi_logloss: 0.738286\n",
      "[600]\ttraining's multi_logloss: 0.605746\tvalid_1's multi_logloss: 0.71503\n",
      "[900]\ttraining's multi_logloss: 0.556884\tvalid_1's multi_logloss: 0.714637\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's multi_logloss: 0.581071\tvalid_1's multi_logloss: 0.714075\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.671484\tvalid_1's multi_logloss: 0.814644\n",
      "[600]\ttraining's multi_logloss: 0.597107\tvalid_1's multi_logloss: 0.797809\n",
      "[900]\ttraining's multi_logloss: 0.549013\tvalid_1's multi_logloss: 0.794587\n",
      "Early stopping, best iteration is:\n",
      "[824]\ttraining's multi_logloss: 0.55993\tvalid_1's multi_logloss: 0.794354\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.681963\tvalid_1's multi_logloss: 0.76583\n",
      "[600]\ttraining's multi_logloss: 0.606266\tvalid_1's multi_logloss: 0.738587\n",
      "[900]\ttraining's multi_logloss: 0.556957\tvalid_1's multi_logloss: 0.732512\n",
      "[1200]\ttraining's multi_logloss: 0.518316\tvalid_1's multi_logloss: 0.728855\n",
      "[1500]\ttraining's multi_logloss: 0.485315\tvalid_1's multi_logloss: 0.725429\n",
      "[1800]\ttraining's multi_logloss: 0.455689\tvalid_1's multi_logloss: 0.728627\n",
      "Early stopping, best iteration is:\n",
      "[1635]\ttraining's multi_logloss: 0.471726\tvalid_1's multi_logloss: 0.725145\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.669985\tvalid_1's multi_logloss: 0.75064\n",
      "[600]\ttraining's multi_logloss: 0.595422\tvalid_1's multi_logloss: 0.730477\n",
      "[900]\ttraining's multi_logloss: 0.547093\tvalid_1's multi_logloss: 0.73014\n",
      "Early stopping, best iteration is:\n",
      "[690]\ttraining's multi_logloss: 0.579624\tvalid_1's multi_logloss: 0.728505\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.670142\tvalid_1's multi_logloss: 0.762938\n",
      "[600]\ttraining's multi_logloss: 0.594479\tvalid_1's multi_logloss: 0.736712\n",
      "[900]\ttraining's multi_logloss: 0.545137\tvalid_1's multi_logloss: 0.724318\n",
      "[1200]\ttraining's multi_logloss: 0.505169\tvalid_1's multi_logloss: 0.717473\n",
      "[1500]\ttraining's multi_logloss: 0.470819\tvalid_1's multi_logloss: 0.719655\n",
      "Early stopping, best iteration is:\n",
      "[1258]\ttraining's multi_logloss: 0.498206\tvalid_1's multi_logloss: 0.715922\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.668766\tvalid_1's multi_logloss: 0.775539\n",
      "[600]\ttraining's multi_logloss: 0.592577\tvalid_1's multi_logloss: 0.771888\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttraining's multi_logloss: 0.611515\tvalid_1's multi_logloss: 0.770421\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.683067\tvalid_1's multi_logloss: 0.720542\n",
      "[600]\ttraining's multi_logloss: 0.607632\tvalid_1's multi_logloss: 0.691039\n",
      "[900]\ttraining's multi_logloss: 0.559954\tvalid_1's multi_logloss: 0.683405\n",
      "[1200]\ttraining's multi_logloss: 0.519982\tvalid_1's multi_logloss: 0.681868\n",
      "[1500]\ttraining's multi_logloss: 0.485822\tvalid_1's multi_logloss: 0.682085\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's multi_logloss: 0.504721\tvalid_1's multi_logloss: 0.680987\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.66928\tvalid_1's multi_logloss: 0.766182\n",
      "[600]\ttraining's multi_logloss: 0.592928\tvalid_1's multi_logloss: 0.743109\n",
      "[900]\ttraining's multi_logloss: 0.541677\tvalid_1's multi_logloss: 0.740143\n",
      "[1200]\ttraining's multi_logloss: 0.500404\tvalid_1's multi_logloss: 0.738611\n",
      "[1500]\ttraining's multi_logloss: 0.465877\tvalid_1's multi_logloss: 0.740946\n",
      "Early stopping, best iteration is:\n",
      "[1217]\ttraining's multi_logloss: 0.498319\tvalid_1's multi_logloss: 0.738352\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.670902\tvalid_1's multi_logloss: 0.768536\n",
      "[600]\ttraining's multi_logloss: 0.593722\tvalid_1's multi_logloss: 0.751297\n",
      "[900]\ttraining's multi_logloss: 0.545359\tvalid_1's multi_logloss: 0.751739\n",
      "Early stopping, best iteration is:\n",
      "[732]\ttraining's multi_logloss: 0.571087\tvalid_1's multi_logloss: 0.75006\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.67749\tvalid_1's multi_logloss: 0.70078\n",
      "[600]\ttraining's multi_logloss: 0.601953\tvalid_1's multi_logloss: 0.666778\n",
      "[900]\ttraining's multi_logloss: 0.552941\tvalid_1's multi_logloss: 0.656948\n",
      "[1200]\ttraining's multi_logloss: 0.513127\tvalid_1's multi_logloss: 0.649377\n",
      "[1500]\ttraining's multi_logloss: 0.479425\tvalid_1's multi_logloss: 0.646174\n",
      "[1800]\ttraining's multi_logloss: 0.449801\tvalid_1's multi_logloss: 0.647392\n",
      "Early stopping, best iteration is:\n",
      "[1630]\ttraining's multi_logloss: 0.466167\tvalid_1's multi_logloss: 0.645683\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.677368\tvalid_1's multi_logloss: 0.774131\n",
      "[600]\ttraining's multi_logloss: 0.601485\tvalid_1's multi_logloss: 0.750934\n",
      "[900]\ttraining's multi_logloss: 0.55064\tvalid_1's multi_logloss: 0.74598\n",
      "[1200]\ttraining's multi_logloss: 0.509664\tvalid_1's multi_logloss: 0.746024\n",
      "[1500]\ttraining's multi_logloss: 0.47459\tvalid_1's multi_logloss: 0.742496\n",
      "[1800]\ttraining's multi_logloss: 0.444609\tvalid_1's multi_logloss: 0.742098\n",
      "Early stopping, best iteration is:\n",
      "[1684]\ttraining's multi_logloss: 0.455686\tvalid_1's multi_logloss: 0.741007\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.67485\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.79        37\n",
      "           1       0.56      0.41      0.48       205\n",
      "           2       0.72      0.57      0.64       191\n",
      "           3       0.86      0.83      0.84       461\n",
      "           4       0.60      0.47      0.52        45\n",
      "           5       0.65      0.52      0.58       126\n",
      "           6       0.61      0.38      0.47        50\n",
      "           7       0.65      0.60      0.63       334\n",
      "           8       0.72      0.79      0.76      1318\n",
      "           9       0.88      0.90      0.89        77\n",
      "          10       0.81      0.84      0.83      1639\n",
      "\n",
      "    accuracy                           0.76      4483\n",
      "   macro avg       0.72      0.64      0.67      4483\n",
      "weighted avg       0.76      0.76      0.76      4483\n",
      "\n",
      "509 rows were filled. (confidence>0.925)\n",
      "filled test labels: [  8   5  13  66   1  10   0   1 150  18 237]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.600699\tvalid_1's multi_logloss: 0.794372\n",
      "[600]\ttraining's multi_logloss: 0.531361\tvalid_1's multi_logloss: 0.774501\n",
      "[900]\ttraining's multi_logloss: 0.487033\tvalid_1's multi_logloss: 0.769335\n",
      "[1200]\ttraining's multi_logloss: 0.450938\tvalid_1's multi_logloss: 0.768012\n",
      "[1500]\ttraining's multi_logloss: 0.420226\tvalid_1's multi_logloss: 0.767434\n",
      "Early stopping, best iteration is:\n",
      "[1425]\ttraining's multi_logloss: 0.427756\tvalid_1's multi_logloss: 0.766424\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.601623\tvalid_1's multi_logloss: 0.715839\n",
      "[600]\ttraining's multi_logloss: 0.531562\tvalid_1's multi_logloss: 0.698552\n",
      "[900]\ttraining's multi_logloss: 0.485088\tvalid_1's multi_logloss: 0.701712\n",
      "Early stopping, best iteration is:\n",
      "[650]\ttraining's multi_logloss: 0.52276\tvalid_1's multi_logloss: 0.69838\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.6049\tvalid_1's multi_logloss: 0.724757\n",
      "[600]\ttraining's multi_logloss: 0.536022\tvalid_1's multi_logloss: 0.701655\n",
      "[900]\ttraining's multi_logloss: 0.491389\tvalid_1's multi_logloss: 0.697555\n",
      "[1200]\ttraining's multi_logloss: 0.454673\tvalid_1's multi_logloss: 0.691536\n",
      "[1500]\ttraining's multi_logloss: 0.42354\tvalid_1's multi_logloss: 0.691313\n",
      "Early stopping, best iteration is:\n",
      "[1313]\ttraining's multi_logloss: 0.442324\tvalid_1's multi_logloss: 0.690924\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.613747\tvalid_1's multi_logloss: 0.641101\n",
      "[600]\ttraining's multi_logloss: 0.544117\tvalid_1's multi_logloss: 0.609278\n",
      "[900]\ttraining's multi_logloss: 0.498811\tvalid_1's multi_logloss: 0.607094\n",
      "Early stopping, best iteration is:\n",
      "[687]\ttraining's multi_logloss: 0.529555\tvalid_1's multi_logloss: 0.6063\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.614199\tvalid_1's multi_logloss: 0.690423\n",
      "[600]\ttraining's multi_logloss: 0.545885\tvalid_1's multi_logloss: 0.675236\n",
      "[900]\ttraining's multi_logloss: 0.501375\tvalid_1's multi_logloss: 0.672703\n",
      "[1200]\ttraining's multi_logloss: 0.465164\tvalid_1's multi_logloss: 0.672684\n",
      "Early stopping, best iteration is:\n",
      "[1003]\ttraining's multi_logloss: 0.488345\tvalid_1's multi_logloss: 0.671708\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.614216\tvalid_1's multi_logloss: 0.631828\n",
      "[600]\ttraining's multi_logloss: 0.544206\tvalid_1's multi_logloss: 0.61163\n",
      "[900]\ttraining's multi_logloss: 0.498675\tvalid_1's multi_logloss: 0.610876\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttraining's multi_logloss: 0.515872\tvalid_1's multi_logloss: 0.609238\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.604882\tvalid_1's multi_logloss: 0.806631\n",
      "[600]\ttraining's multi_logloss: 0.535667\tvalid_1's multi_logloss: 0.805578\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's multi_logloss: 0.574329\tvalid_1's multi_logloss: 0.799802\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.605583\tvalid_1's multi_logloss: 0.655315\n",
      "[600]\ttraining's multi_logloss: 0.535832\tvalid_1's multi_logloss: 0.63333\n",
      "[900]\ttraining's multi_logloss: 0.490164\tvalid_1's multi_logloss: 0.627645\n",
      "[1200]\ttraining's multi_logloss: 0.454253\tvalid_1's multi_logloss: 0.625817\n",
      "[1500]\ttraining's multi_logloss: 0.423024\tvalid_1's multi_logloss: 0.626041\n",
      "Early stopping, best iteration is:\n",
      "[1299]\ttraining's multi_logloss: 0.443363\tvalid_1's multi_logloss: 0.625154\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.605544\tvalid_1's multi_logloss: 0.647624\n",
      "[600]\ttraining's multi_logloss: 0.536329\tvalid_1's multi_logloss: 0.629995\n",
      "[900]\ttraining's multi_logloss: 0.490883\tvalid_1's multi_logloss: 0.628765\n",
      "[1200]\ttraining's multi_logloss: 0.454978\tvalid_1's multi_logloss: 0.628564\n",
      "[1500]\ttraining's multi_logloss: 0.424654\tvalid_1's multi_logloss: 0.629522\n",
      "Early stopping, best iteration is:\n",
      "[1281]\ttraining's multi_logloss: 0.446496\tvalid_1's multi_logloss: 0.628175\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.613695\tvalid_1's multi_logloss: 0.61932\n",
      "[600]\ttraining's multi_logloss: 0.542463\tvalid_1's multi_logloss: 0.605008\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's multi_logloss: 0.562863\tvalid_1's multi_logloss: 0.6044\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.608026\tvalid_1's multi_logloss: 0.72276\n",
      "[600]\ttraining's multi_logloss: 0.539213\tvalid_1's multi_logloss: 0.708014\n",
      "[900]\ttraining's multi_logloss: 0.495274\tvalid_1's multi_logloss: 0.703298\n",
      "Early stopping, best iteration is:\n",
      "[886]\ttraining's multi_logloss: 0.497161\tvalid_1's multi_logloss: 0.703219\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.604239\tvalid_1's multi_logloss: 0.708015\n",
      "[600]\ttraining's multi_logloss: 0.533599\tvalid_1's multi_logloss: 0.690689\n",
      "[900]\ttraining's multi_logloss: 0.486151\tvalid_1's multi_logloss: 0.690327\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttraining's multi_logloss: 0.522519\tvalid_1's multi_logloss: 0.689695\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.604146\tvalid_1's multi_logloss: 0.645861\n",
      "[600]\ttraining's multi_logloss: 0.535213\tvalid_1's multi_logloss: 0.626741\n",
      "[900]\ttraining's multi_logloss: 0.489617\tvalid_1's multi_logloss: 0.628168\n",
      "Early stopping, best iteration is:\n",
      "[609]\ttraining's multi_logloss: 0.53362\tvalid_1's multi_logloss: 0.626578\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.611414\tvalid_1's multi_logloss: 0.612956\n",
      "[600]\ttraining's multi_logloss: 0.543273\tvalid_1's multi_logloss: 0.590098\n",
      "[900]\ttraining's multi_logloss: 0.498888\tvalid_1's multi_logloss: 0.582498\n",
      "[1200]\ttraining's multi_logloss: 0.463725\tvalid_1's multi_logloss: 0.584094\n",
      "Early stopping, best iteration is:\n",
      "[1006]\ttraining's multi_logloss: 0.485654\tvalid_1's multi_logloss: 0.582085\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.612533\tvalid_1's multi_logloss: 0.669081\n",
      "[600]\ttraining's multi_logloss: 0.541953\tvalid_1's multi_logloss: 0.650098\n",
      "[900]\ttraining's multi_logloss: 0.497257\tvalid_1's multi_logloss: 0.650977\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's multi_logloss: 0.52784\tvalid_1's multi_logloss: 0.649637\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.69716\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        45\n",
      "           1       0.54      0.43      0.48       210\n",
      "           2       0.72      0.58      0.64       204\n",
      "           3       0.87      0.85      0.86       527\n",
      "           4       0.76      0.61      0.67        46\n",
      "           5       0.67      0.54      0.60       136\n",
      "           6       0.59      0.34      0.43        50\n",
      "           7       0.67      0.62      0.64       335\n",
      "           8       0.75      0.82      0.78      1468\n",
      "           9       0.92      0.91      0.91        95\n",
      "          10       0.84      0.86      0.85      1876\n",
      "\n",
      "    accuracy                           0.79      4992\n",
      "   macro avg       0.74      0.66      0.70      4992\n",
      "weighted avg       0.78      0.79      0.78      4992\n",
      "\n",
      "401 rows were filled. (confidence>0.9)\n",
      "filled test labels: [  4   2  15  52   2  10   1   3 187   2 123]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.569179\tvalid_1's multi_logloss: 0.579867\n",
      "[600]\ttraining's multi_logloss: 0.504727\tvalid_1's multi_logloss: 0.555332\n",
      "[900]\ttraining's multi_logloss: 0.463539\tvalid_1's multi_logloss: 0.550215\n",
      "[1200]\ttraining's multi_logloss: 0.429372\tvalid_1's multi_logloss: 0.550647\n",
      "Early stopping, best iteration is:\n",
      "[984]\ttraining's multi_logloss: 0.45329\tvalid_1's multi_logloss: 0.549264\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.558102\tvalid_1's multi_logloss: 0.636691\n",
      "[600]\ttraining's multi_logloss: 0.492474\tvalid_1's multi_logloss: 0.617325\n",
      "Early stopping, best iteration is:\n",
      "[536]\ttraining's multi_logloss: 0.503736\tvalid_1's multi_logloss: 0.617003\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.559412\tvalid_1's multi_logloss: 0.695975\n",
      "[600]\ttraining's multi_logloss: 0.4939\tvalid_1's multi_logloss: 0.68684\n",
      "Early stopping, best iteration is:\n",
      "[555]\ttraining's multi_logloss: 0.501363\tvalid_1's multi_logloss: 0.686009\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.563592\tvalid_1's multi_logloss: 0.633456\n",
      "[600]\ttraining's multi_logloss: 0.497116\tvalid_1's multi_logloss: 0.615134\n",
      "[900]\ttraining's multi_logloss: 0.455075\tvalid_1's multi_logloss: 0.615695\n",
      "Early stopping, best iteration is:\n",
      "[657]\ttraining's multi_logloss: 0.488203\tvalid_1's multi_logloss: 0.614396\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.57159\tvalid_1's multi_logloss: 0.574014\n",
      "[600]\ttraining's multi_logloss: 0.505621\tvalid_1's multi_logloss: 0.557091\n",
      "[900]\ttraining's multi_logloss: 0.464035\tvalid_1's multi_logloss: 0.553222\n",
      "[1200]\ttraining's multi_logloss: 0.431281\tvalid_1's multi_logloss: 0.552417\n",
      "[1500]\ttraining's multi_logloss: 0.403308\tvalid_1's multi_logloss: 0.550708\n",
      "[1800]\ttraining's multi_logloss: 0.378629\tvalid_1's multi_logloss: 0.55079\n",
      "Early stopping, best iteration is:\n",
      "[1694]\ttraining's multi_logloss: 0.387243\tvalid_1's multi_logloss: 0.550285\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.568954\tvalid_1's multi_logloss: 0.675407\n",
      "[600]\ttraining's multi_logloss: 0.503888\tvalid_1's multi_logloss: 0.650427\n",
      "[900]\ttraining's multi_logloss: 0.462326\tvalid_1's multi_logloss: 0.648109\n",
      "[1200]\ttraining's multi_logloss: 0.429192\tvalid_1's multi_logloss: 0.643105\n",
      "[1500]\ttraining's multi_logloss: 0.400765\tvalid_1's multi_logloss: 0.639832\n",
      "[1800]\ttraining's multi_logloss: 0.376157\tvalid_1's multi_logloss: 0.638925\n",
      "Early stopping, best iteration is:\n",
      "[1677]\ttraining's multi_logloss: 0.385813\tvalid_1's multi_logloss: 0.63846\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.573794\tvalid_1's multi_logloss: 0.617216\n",
      "[600]\ttraining's multi_logloss: 0.508688\tvalid_1's multi_logloss: 0.602209\n",
      "[900]\ttraining's multi_logloss: 0.468565\tvalid_1's multi_logloss: 0.599177\n",
      "[1200]\ttraining's multi_logloss: 0.435803\tvalid_1's multi_logloss: 0.594449\n",
      "[1500]\ttraining's multi_logloss: 0.407148\tvalid_1's multi_logloss: 0.59393\n",
      "[1800]\ttraining's multi_logloss: 0.382398\tvalid_1's multi_logloss: 0.592344\n",
      "[2100]\ttraining's multi_logloss: 0.360122\tvalid_1's multi_logloss: 0.591797\n",
      "[2400]\ttraining's multi_logloss: 0.339536\tvalid_1's multi_logloss: 0.591657\n",
      "Early stopping, best iteration is:\n",
      "[2180]\ttraining's multi_logloss: 0.354416\tvalid_1's multi_logloss: 0.5911\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.567974\tvalid_1's multi_logloss: 0.576536\n",
      "[600]\ttraining's multi_logloss: 0.50198\tvalid_1's multi_logloss: 0.554697\n",
      "[900]\ttraining's multi_logloss: 0.459976\tvalid_1's multi_logloss: 0.547023\n",
      "[1200]\ttraining's multi_logloss: 0.425901\tvalid_1's multi_logloss: 0.544623\n",
      "[1500]\ttraining's multi_logloss: 0.397402\tvalid_1's multi_logloss: 0.546246\n",
      "Early stopping, best iteration is:\n",
      "[1208]\ttraining's multi_logloss: 0.425123\tvalid_1's multi_logloss: 0.544495\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.567127\tvalid_1's multi_logloss: 0.625996\n",
      "[600]\ttraining's multi_logloss: 0.501786\tvalid_1's multi_logloss: 0.602824\n",
      "[900]\ttraining's multi_logloss: 0.460087\tvalid_1's multi_logloss: 0.6032\n",
      "Early stopping, best iteration is:\n",
      "[723]\ttraining's multi_logloss: 0.483355\tvalid_1's multi_logloss: 0.601563\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.557907\tvalid_1's multi_logloss: 0.736357\n",
      "[600]\ttraining's multi_logloss: 0.49333\tvalid_1's multi_logloss: 0.722934\n",
      "[900]\ttraining's multi_logloss: 0.45047\tvalid_1's multi_logloss: 0.724032\n",
      "Early stopping, best iteration is:\n",
      "[637]\ttraining's multi_logloss: 0.487358\tvalid_1's multi_logloss: 0.722476\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.569024\tvalid_1's multi_logloss: 0.674925\n",
      "[600]\ttraining's multi_logloss: 0.501955\tvalid_1's multi_logloss: 0.648147\n",
      "[900]\ttraining's multi_logloss: 0.459389\tvalid_1's multi_logloss: 0.649433\n",
      "Early stopping, best iteration is:\n",
      "[694]\ttraining's multi_logloss: 0.486944\tvalid_1's multi_logloss: 0.646598\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.564001\tvalid_1's multi_logloss: 0.610619\n",
      "[600]\ttraining's multi_logloss: 0.498211\tvalid_1's multi_logloss: 0.596589\n",
      "[900]\ttraining's multi_logloss: 0.454931\tvalid_1's multi_logloss: 0.594581\n",
      "[1200]\ttraining's multi_logloss: 0.420854\tvalid_1's multi_logloss: 0.593889\n",
      "Early stopping, best iteration is:\n",
      "[1125]\ttraining's multi_logloss: 0.428525\tvalid_1's multi_logloss: 0.593224\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.561737\tvalid_1's multi_logloss: 0.640302\n",
      "[600]\ttraining's multi_logloss: 0.497478\tvalid_1's multi_logloss: 0.619555\n",
      "[900]\ttraining's multi_logloss: 0.455379\tvalid_1's multi_logloss: 0.617965\n",
      "[1200]\ttraining's multi_logloss: 0.420904\tvalid_1's multi_logloss: 0.617077\n",
      "Early stopping, best iteration is:\n",
      "[1152]\ttraining's multi_logloss: 0.426096\tvalid_1's multi_logloss: 0.61689\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.57029\tvalid_1's multi_logloss: 0.592508\n",
      "[600]\ttraining's multi_logloss: 0.505019\tvalid_1's multi_logloss: 0.572288\n",
      "[900]\ttraining's multi_logloss: 0.463434\tvalid_1's multi_logloss: 0.571596\n",
      "[1200]\ttraining's multi_logloss: 0.430355\tvalid_1's multi_logloss: 0.570672\n",
      "[1500]\ttraining's multi_logloss: 0.401616\tvalid_1's multi_logloss: 0.569412\n",
      "Early stopping, best iteration is:\n",
      "[1486]\ttraining's multi_logloss: 0.402814\tvalid_1's multi_logloss: 0.569199\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.567586\tvalid_1's multi_logloss: 0.643175\n",
      "[600]\ttraining's multi_logloss: 0.502222\tvalid_1's multi_logloss: 0.623741\n",
      "[900]\ttraining's multi_logloss: 0.461119\tvalid_1's multi_logloss: 0.622901\n",
      "[1200]\ttraining's multi_logloss: 0.428729\tvalid_1's multi_logloss: 0.623929\n",
      "Early stopping, best iteration is:\n",
      "[967]\ttraining's multi_logloss: 0.453272\tvalid_1's multi_logloss: 0.622197\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.70697\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83        49\n",
      "           1       0.56      0.45      0.50       212\n",
      "           2       0.78      0.63      0.70       219\n",
      "           3       0.87      0.85      0.86       579\n",
      "           4       0.73      0.56      0.64        48\n",
      "           5       0.70      0.59      0.64       146\n",
      "           6       0.52      0.33      0.40        51\n",
      "           7       0.64      0.63      0.63       338\n",
      "           8       0.78      0.83      0.80      1655\n",
      "           9       0.93      0.90      0.91        97\n",
      "          10       0.85      0.87      0.86      1999\n",
      "\n",
      "    accuracy                           0.80      5393\n",
      "   macro avg       0.75      0.68      0.71      5393\n",
      "weighted avg       0.80      0.80      0.80      5393\n",
      "\n",
      "340 rows were filled. (confidence>0.875)\n",
      "filled test labels: [  3   6   3  34   5   4   0  21 176   3  85]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.539211\tvalid_1's multi_logloss: 0.58091\n",
      "[600]\ttraining's multi_logloss: 0.477672\tvalid_1's multi_logloss: 0.553194\n",
      "[900]\ttraining's multi_logloss: 0.438265\tvalid_1's multi_logloss: 0.545767\n",
      "[1200]\ttraining's multi_logloss: 0.406077\tvalid_1's multi_logloss: 0.543217\n",
      "[1500]\ttraining's multi_logloss: 0.378401\tvalid_1's multi_logloss: 0.542011\n",
      "[1800]\ttraining's multi_logloss: 0.354012\tvalid_1's multi_logloss: 0.5423\n",
      "Early stopping, best iteration is:\n",
      "[1659]\ttraining's multi_logloss: 0.364857\tvalid_1's multi_logloss: 0.541516\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.532076\tvalid_1's multi_logloss: 0.630678\n",
      "[600]\ttraining's multi_logloss: 0.469667\tvalid_1's multi_logloss: 0.614298\n",
      "[900]\ttraining's multi_logloss: 0.428201\tvalid_1's multi_logloss: 0.609737\n",
      "[1200]\ttraining's multi_logloss: 0.395272\tvalid_1's multi_logloss: 0.608013\n",
      "[1500]\ttraining's multi_logloss: 0.367292\tvalid_1's multi_logloss: 0.609371\n",
      "Early stopping, best iteration is:\n",
      "[1258]\ttraining's multi_logloss: 0.3894\tvalid_1's multi_logloss: 0.607774\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.529213\tvalid_1's multi_logloss: 0.617129\n",
      "[600]\ttraining's multi_logloss: 0.466719\tvalid_1's multi_logloss: 0.598576\n",
      "[900]\ttraining's multi_logloss: 0.426093\tvalid_1's multi_logloss: 0.598767\n",
      "Early stopping, best iteration is:\n",
      "[656]\ttraining's multi_logloss: 0.458239\tvalid_1's multi_logloss: 0.598088\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.53495\tvalid_1's multi_logloss: 0.631171\n",
      "[600]\ttraining's multi_logloss: 0.471704\tvalid_1's multi_logloss: 0.615727\n",
      "[900]\ttraining's multi_logloss: 0.431629\tvalid_1's multi_logloss: 0.61606\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's multi_logloss: 0.462992\tvalid_1's multi_logloss: 0.615135\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.536344\tvalid_1's multi_logloss: 0.638766\n",
      "[600]\ttraining's multi_logloss: 0.473652\tvalid_1's multi_logloss: 0.629039\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's multi_logloss: 0.484436\tvalid_1's multi_logloss: 0.628423\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.544391\tvalid_1's multi_logloss: 0.594033\n",
      "[600]\ttraining's multi_logloss: 0.480981\tvalid_1's multi_logloss: 0.570219\n",
      "[900]\ttraining's multi_logloss: 0.442602\tvalid_1's multi_logloss: 0.567432\n",
      "[1200]\ttraining's multi_logloss: 0.411924\tvalid_1's multi_logloss: 0.569095\n",
      "Early stopping, best iteration is:\n",
      "[902]\ttraining's multi_logloss: 0.442355\tvalid_1's multi_logloss: 0.567379\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.53871\tvalid_1's multi_logloss: 0.610263\n",
      "[600]\ttraining's multi_logloss: 0.476708\tvalid_1's multi_logloss: 0.578423\n",
      "[900]\ttraining's multi_logloss: 0.436769\tvalid_1's multi_logloss: 0.571278\n",
      "[1200]\ttraining's multi_logloss: 0.405909\tvalid_1's multi_logloss: 0.569397\n",
      "[1500]\ttraining's multi_logloss: 0.379571\tvalid_1's multi_logloss: 0.567777\n",
      "[1800]\ttraining's multi_logloss: 0.355538\tvalid_1's multi_logloss: 0.567035\n",
      "[2100]\ttraining's multi_logloss: 0.333977\tvalid_1's multi_logloss: 0.56674\n",
      "Early stopping, best iteration is:\n",
      "[1943]\ttraining's multi_logloss: 0.345153\tvalid_1's multi_logloss: 0.566248\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.531694\tvalid_1's multi_logloss: 0.63795\n",
      "[600]\ttraining's multi_logloss: 0.468555\tvalid_1's multi_logloss: 0.622222\n",
      "[900]\ttraining's multi_logloss: 0.427284\tvalid_1's multi_logloss: 0.624413\n",
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's multi_logloss: 0.457431\tvalid_1's multi_logloss: 0.621779\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.538016\tvalid_1's multi_logloss: 0.583247\n",
      "[600]\ttraining's multi_logloss: 0.476481\tvalid_1's multi_logloss: 0.565451\n",
      "[900]\ttraining's multi_logloss: 0.436859\tvalid_1's multi_logloss: 0.564816\n",
      "Early stopping, best iteration is:\n",
      "[886]\ttraining's multi_logloss: 0.43854\tvalid_1's multi_logloss: 0.564675\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.534166\tvalid_1's multi_logloss: 0.63881\n",
      "[600]\ttraining's multi_logloss: 0.473365\tvalid_1's multi_logloss: 0.622075\n",
      "[900]\ttraining's multi_logloss: 0.43494\tvalid_1's multi_logloss: 0.616047\n",
      "[1200]\ttraining's multi_logloss: 0.403199\tvalid_1's multi_logloss: 0.610815\n",
      "[1500]\ttraining's multi_logloss: 0.376436\tvalid_1's multi_logloss: 0.605048\n",
      "[1800]\ttraining's multi_logloss: 0.35313\tvalid_1's multi_logloss: 0.604877\n",
      "Early stopping, best iteration is:\n",
      "[1575]\ttraining's multi_logloss: 0.370381\tvalid_1's multi_logloss: 0.604433\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.540788\tvalid_1's multi_logloss: 0.603144\n",
      "[600]\ttraining's multi_logloss: 0.477329\tvalid_1's multi_logloss: 0.582726\n",
      "[900]\ttraining's multi_logloss: 0.437665\tvalid_1's multi_logloss: 0.575123\n",
      "[1200]\ttraining's multi_logloss: 0.40606\tvalid_1's multi_logloss: 0.575864\n",
      "Early stopping, best iteration is:\n",
      "[1021]\ttraining's multi_logloss: 0.424088\tvalid_1's multi_logloss: 0.574328\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.533179\tvalid_1's multi_logloss: 0.622493\n",
      "[600]\ttraining's multi_logloss: 0.47089\tvalid_1's multi_logloss: 0.60083\n",
      "[900]\ttraining's multi_logloss: 0.430256\tvalid_1's multi_logloss: 0.594809\n",
      "[1200]\ttraining's multi_logloss: 0.397636\tvalid_1's multi_logloss: 0.596323\n",
      "Early stopping, best iteration is:\n",
      "[917]\ttraining's multi_logloss: 0.428237\tvalid_1's multi_logloss: 0.594588\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.534243\tvalid_1's multi_logloss: 0.584239\n",
      "[600]\ttraining's multi_logloss: 0.470983\tvalid_1's multi_logloss: 0.57793\n",
      "[900]\ttraining's multi_logloss: 0.430927\tvalid_1's multi_logloss: 0.578402\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttraining's multi_logloss: 0.467402\tvalid_1's multi_logloss: 0.577535\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.54199\tvalid_1's multi_logloss: 0.566406\n",
      "[600]\ttraining's multi_logloss: 0.479244\tvalid_1's multi_logloss: 0.54867\n",
      "[900]\ttraining's multi_logloss: 0.439795\tvalid_1's multi_logloss: 0.551265\n",
      "Early stopping, best iteration is:\n",
      "[665]\ttraining's multi_logloss: 0.46972\tvalid_1's multi_logloss: 0.548394\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.544404\tvalid_1's multi_logloss: 0.579833\n",
      "[600]\ttraining's multi_logloss: 0.482991\tvalid_1's multi_logloss: 0.560164\n",
      "[900]\ttraining's multi_logloss: 0.443449\tvalid_1's multi_logloss: 0.556004\n",
      "[1200]\ttraining's multi_logloss: 0.412268\tvalid_1's multi_logloss: 0.552706\n",
      "[1500]\ttraining's multi_logloss: 0.385932\tvalid_1's multi_logloss: 0.550615\n",
      "Early stopping, best iteration is:\n",
      "[1482]\ttraining's multi_logloss: 0.387475\tvalid_1's multi_logloss: 0.550126\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.71954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81        52\n",
      "           1       0.57      0.45      0.50       218\n",
      "           2       0.74      0.63      0.68       222\n",
      "           3       0.89      0.87      0.88       613\n",
      "           4       0.77      0.62      0.69        53\n",
      "           5       0.64      0.59      0.61       150\n",
      "           6       0.60      0.41      0.49        51\n",
      "           7       0.66      0.64      0.65       359\n",
      "           8       0.80      0.85      0.82      1831\n",
      "           9       0.91      0.91      0.91       100\n",
      "          10       0.86      0.88      0.87      2084\n",
      "\n",
      "    accuracy                           0.81      5733\n",
      "   macro avg       0.75      0.69      0.72      5733\n",
      "weighted avg       0.81      0.81      0.81      5733\n",
      "\n",
      "260 rows were filled. (confidence>0.85)\n",
      "filled test labels: [  1   2  10  16   4   8   2  26 126   2  63]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.518039\tvalid_1's multi_logloss: 0.594807\n",
      "[600]\ttraining's multi_logloss: 0.45681\tvalid_1's multi_logloss: 0.57916\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's multi_logloss: 0.458381\tvalid_1's multi_logloss: 0.579014\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.514026\tvalid_1's multi_logloss: 0.583775\n",
      "[600]\ttraining's multi_logloss: 0.451116\tvalid_1's multi_logloss: 0.570469\n",
      "[900]\ttraining's multi_logloss: 0.413384\tvalid_1's multi_logloss: 0.573677\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's multi_logloss: 0.44944\tvalid_1's multi_logloss: 0.570121\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.513819\tvalid_1's multi_logloss: 0.637821\n",
      "[600]\ttraining's multi_logloss: 0.453306\tvalid_1's multi_logloss: 0.622914\n",
      "[900]\ttraining's multi_logloss: 0.415024\tvalid_1's multi_logloss: 0.621727\n",
      "Early stopping, best iteration is:\n",
      "[868]\ttraining's multi_logloss: 0.418676\tvalid_1's multi_logloss: 0.621253\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.522667\tvalid_1's multi_logloss: 0.529327\n",
      "[600]\ttraining's multi_logloss: 0.461839\tvalid_1's multi_logloss: 0.514751\n",
      "[900]\ttraining's multi_logloss: 0.421879\tvalid_1's multi_logloss: 0.514907\n",
      "Early stopping, best iteration is:\n",
      "[743]\ttraining's multi_logloss: 0.441396\tvalid_1's multi_logloss: 0.513708\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.515089\tvalid_1's multi_logloss: 0.657122\n",
      "[600]\ttraining's multi_logloss: 0.454126\tvalid_1's multi_logloss: 0.639887\n",
      "[900]\ttraining's multi_logloss: 0.416099\tvalid_1's multi_logloss: 0.641111\n",
      "Early stopping, best iteration is:\n",
      "[713]\ttraining's multi_logloss: 0.43842\tvalid_1's multi_logloss: 0.639047\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.524599\tvalid_1's multi_logloss: 0.532579\n",
      "[600]\ttraining's multi_logloss: 0.463233\tvalid_1's multi_logloss: 0.523375\n",
      "[900]\ttraining's multi_logloss: 0.425051\tvalid_1's multi_logloss: 0.525609\n",
      "Early stopping, best iteration is:\n",
      "[640]\ttraining's multi_logloss: 0.45751\tvalid_1's multi_logloss: 0.522666\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.519462\tvalid_1's multi_logloss: 0.603485\n",
      "[600]\ttraining's multi_logloss: 0.458509\tvalid_1's multi_logloss: 0.582276\n",
      "[900]\ttraining's multi_logloss: 0.420271\tvalid_1's multi_logloss: 0.578582\n",
      "[1200]\ttraining's multi_logloss: 0.389857\tvalid_1's multi_logloss: 0.57843\n",
      "Early stopping, best iteration is:\n",
      "[982]\ttraining's multi_logloss: 0.411319\tvalid_1's multi_logloss: 0.578035\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.514909\tvalid_1's multi_logloss: 0.574228\n",
      "[600]\ttraining's multi_logloss: 0.455497\tvalid_1's multi_logloss: 0.559215\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's multi_logloss: 0.463308\tvalid_1's multi_logloss: 0.55903\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.516464\tvalid_1's multi_logloss: 0.614999\n",
      "[600]\ttraining's multi_logloss: 0.454768\tvalid_1's multi_logloss: 0.608663\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's multi_logloss: 0.472248\tvalid_1's multi_logloss: 0.608371\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.523335\tvalid_1's multi_logloss: 0.529024\n",
      "[600]\ttraining's multi_logloss: 0.46277\tvalid_1's multi_logloss: 0.496065\n",
      "[900]\ttraining's multi_logloss: 0.423373\tvalid_1's multi_logloss: 0.486364\n",
      "[1200]\ttraining's multi_logloss: 0.392463\tvalid_1's multi_logloss: 0.483904\n",
      "[1500]\ttraining's multi_logloss: 0.366756\tvalid_1's multi_logloss: 0.48166\n",
      "[1800]\ttraining's multi_logloss: 0.344066\tvalid_1's multi_logloss: 0.480523\n",
      "[2100]\ttraining's multi_logloss: 0.323693\tvalid_1's multi_logloss: 0.480186\n",
      "[2400]\ttraining's multi_logloss: 0.305151\tvalid_1's multi_logloss: 0.479359\n",
      "[2700]\ttraining's multi_logloss: 0.287951\tvalid_1's multi_logloss: 0.479578\n",
      "Early stopping, best iteration is:\n",
      "[2537]\ttraining's multi_logloss: 0.297237\tvalid_1's multi_logloss: 0.479137\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.520463\tvalid_1's multi_logloss: 0.617401\n",
      "[600]\ttraining's multi_logloss: 0.459059\tvalid_1's multi_logloss: 0.592766\n",
      "[900]\ttraining's multi_logloss: 0.420643\tvalid_1's multi_logloss: 0.588375\n",
      "[1200]\ttraining's multi_logloss: 0.389455\tvalid_1's multi_logloss: 0.586095\n",
      "[1500]\ttraining's multi_logloss: 0.363156\tvalid_1's multi_logloss: 0.585379\n",
      "Early stopping, best iteration is:\n",
      "[1467]\ttraining's multi_logloss: 0.365803\tvalid_1's multi_logloss: 0.585056\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.51969\tvalid_1's multi_logloss: 0.53971\n",
      "[600]\ttraining's multi_logloss: 0.456961\tvalid_1's multi_logloss: 0.516958\n",
      "[900]\ttraining's multi_logloss: 0.418574\tvalid_1's multi_logloss: 0.510766\n",
      "[1200]\ttraining's multi_logloss: 0.387505\tvalid_1's multi_logloss: 0.50802\n",
      "[1500]\ttraining's multi_logloss: 0.361086\tvalid_1's multi_logloss: 0.504662\n",
      "[1800]\ttraining's multi_logloss: 0.337953\tvalid_1's multi_logloss: 0.501882\n",
      "[2100]\ttraining's multi_logloss: 0.316376\tvalid_1's multi_logloss: 0.50004\n",
      "[2400]\ttraining's multi_logloss: 0.297384\tvalid_1's multi_logloss: 0.50063\n",
      "Early stopping, best iteration is:\n",
      "[2199]\ttraining's multi_logloss: 0.309819\tvalid_1's multi_logloss: 0.499745\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.514058\tvalid_1's multi_logloss: 0.62952\n",
      "[600]\ttraining's multi_logloss: 0.452503\tvalid_1's multi_logloss: 0.613102\n",
      "[900]\ttraining's multi_logloss: 0.413855\tvalid_1's multi_logloss: 0.609031\n",
      "[1200]\ttraining's multi_logloss: 0.382594\tvalid_1's multi_logloss: 0.606817\n",
      "[1500]\ttraining's multi_logloss: 0.356638\tvalid_1's multi_logloss: 0.607479\n",
      "Early stopping, best iteration is:\n",
      "[1312]\ttraining's multi_logloss: 0.372505\tvalid_1's multi_logloss: 0.605986\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.523462\tvalid_1's multi_logloss: 0.507872\n",
      "[600]\ttraining's multi_logloss: 0.463566\tvalid_1's multi_logloss: 0.484325\n",
      "[900]\ttraining's multi_logloss: 0.42426\tvalid_1's multi_logloss: 0.476445\n",
      "[1200]\ttraining's multi_logloss: 0.393228\tvalid_1's multi_logloss: 0.473752\n",
      "[1500]\ttraining's multi_logloss: 0.36727\tvalid_1's multi_logloss: 0.472825\n",
      "Early stopping, best iteration is:\n",
      "[1416]\ttraining's multi_logloss: 0.374136\tvalid_1's multi_logloss: 0.471835\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.51867\tvalid_1's multi_logloss: 0.600645\n",
      "[600]\ttraining's multi_logloss: 0.458853\tvalid_1's multi_logloss: 0.575262\n",
      "[900]\ttraining's multi_logloss: 0.42265\tvalid_1's multi_logloss: 0.568768\n",
      "[1200]\ttraining's multi_logloss: 0.393392\tvalid_1's multi_logloss: 0.56216\n",
      "[1500]\ttraining's multi_logloss: 0.368066\tvalid_1's multi_logloss: 0.55845\n",
      "[1800]\ttraining's multi_logloss: 0.345499\tvalid_1's multi_logloss: 0.558708\n",
      "Early stopping, best iteration is:\n",
      "[1555]\ttraining's multi_logloss: 0.363726\tvalid_1's multi_logloss: 0.557633\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.72529\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82        53\n",
      "           1       0.59      0.46      0.52       220\n",
      "           2       0.78      0.62      0.69       232\n",
      "           3       0.88      0.87      0.87       629\n",
      "           4       0.71      0.63      0.67        57\n",
      "           5       0.68      0.61      0.64       158\n",
      "           6       0.73      0.36      0.48        53\n",
      "           7       0.70      0.65      0.67       385\n",
      "           8       0.81      0.86      0.83      1957\n",
      "           9       0.91      0.90      0.91       102\n",
      "          10       0.86      0.88      0.87      2147\n",
      "\n",
      "    accuracy                           0.82      5993\n",
      "   macro avg       0.77      0.69      0.73      5993\n",
      "weighted avg       0.82      0.82      0.82      5993\n",
      "\n",
      "2099 rows were filled. (confidence>-inf)\n",
      "filled test labels: [  8 132  88 111  28  65  35 260 779  11 582]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pseudo_labeling_threshold in [0.95, 0.925, 0.9, 0.875, 0.85, -np.inf]:\n",
    "    df = df_main.copy()\n",
    "    \n",
    "    \n",
    "    # feature engineering\n",
    "    df[\"genre_name\"] = df[\"genre\"].map(dict(df_genre_labels[[\"labels\", \"genre\"]].values))\n",
    "    df[\"tempo\"] = df[\"tempo\"].map(lambda x: sum(map(int, x.split(\"-\"))) / 2)\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"region\"]).rename(columns={\"unknown\": \"region_unknown\"})], axis=1)\n",
    "    df[\"num_nans\"] = 0\n",
    "    for col in [\n",
    "        \"acousticness\",\n",
    "        \"positiveness\",\n",
    "        \"danceability\",\n",
    "        \"energy\",\n",
    "        \"liveness\",\n",
    "        \"speechiness\",\n",
    "        \"instrumentalness\",\n",
    "    ]:\n",
    "        df[\"num_nans\"] += df[col].isna()\n",
    "    class CountEncoder:\n",
    "        def fit(self, series):\n",
    "            self.counts = series.groupby(series).count()\n",
    "            return self\n",
    "        def transform(self, series):\n",
    "            return series.map(self.counts).fillna(0)\n",
    "        def fit_transform(self, series):\n",
    "            return self.fit(series).transform(series)\n",
    "    columns_count_enc = [\"region\"]\n",
    "    for col in columns_count_enc:\n",
    "        df[\"countenc_\" + col] = CountEncoder().fit_transform(df[col])\n",
    "        df.loc[df[col].isna().values, \"countenc_\" + col] = np.nan\n",
    "    columns_label_enc = [\"region\"]\n",
    "    for col in columns_count_enc:\n",
    "        df[\"labelenc_\" + col] = LabelEncoder().fit_transform(df[col])\n",
    "        df.loc[df[col].isna().values, \"labelenc_\" + col] = np.nan\n",
    "    class GroupFeatureExtractor:  # 参考: https://signate.jp/competitions/449/discussions/lgbm-baseline-lb06240\n",
    "        EX_TRANS_METHODS = [\"deviation\", \"zscore\"]\n",
    "        def __init__(self, group_key, group_values, agg_methods):\n",
    "            self.group_key = group_key\n",
    "            self.group_values = group_values\n",
    "            self.ex_trans_methods = [m for m in agg_methods if m in self.EX_TRANS_METHODS]\n",
    "            self.agg_methods = [m for m in agg_methods if m not in self.ex_trans_methods]\n",
    "            self.df_agg = None\n",
    "        def fit(self, df_train, y=None):\n",
    "            if not self.agg_methods:\n",
    "                return\n",
    "            dfs = []\n",
    "            for agg_method in self.agg_methods:\n",
    "                if callable(agg_method):\n",
    "                    agg_method_name = agg_method.__name__\n",
    "                else:\n",
    "                    agg_method_name = agg_method\n",
    "                df_agg = (df_train[[self.group_key] + self.group_values].groupby(self.group_key).agg(agg_method))\n",
    "                df_agg.columns = self._get_column_names(agg_method_name)\n",
    "                dfs.append(df_agg)\n",
    "            self.df_agg = pd.concat(dfs, axis=1).reset_index()\n",
    "        def transform(self, df_eval):\n",
    "            key = self.group_key\n",
    "            if self.agg_methods:\n",
    "                df_features = pd.merge(df_eval[[self.group_key]], self.df_agg, on=self.group_key, how=\"left\")\n",
    "            else:\n",
    "                df_features = df_eval[[self.group_key]].copy()\n",
    "            if self.ex_trans_methods:\n",
    "                if \"deviation\" in self.ex_trans_methods:\n",
    "                    df_features[self._get_agg_column_names(\"deviation\")] = df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform(\"mean\")\n",
    "                if \"zscore\" in self.ex_trans_methods:\n",
    "                    df_features[self._get_column_names(\"zscore\")] = (df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform(\"mean\")) \\\n",
    "                                                                    / (df_eval[[key]+self.group_values].groupby(key).transform(\"std\") + 1e-8)\n",
    "            df_features.drop(self.group_key, axis=1, inplace=True)\n",
    "            return df_features\n",
    "        def _get_column_names(self, method):\n",
    "            return [f\"agg_{method}_{col}_grpby_{self.group_key}\" for col in self.group_values]\n",
    "        def fit_transform(self, df_train, y=None):\n",
    "            self.fit(df_train, y=y)\n",
    "            return self.transform(df_train)   \n",
    "    df[\"log_tempo\"] = np.log(df[\"tempo\"])\n",
    "    gfe = GroupFeatureExtractor(\n",
    "        \"region\", \n",
    "        ['popularity', 'duration_ms', 'acousticness', 'positiveness', 'danceability', 'loudness', 'energy', 'liveness', 'speechiness', 'instrumentalness', 'log_tempo'],\n",
    "        [\"zscore\"]\n",
    "    )\n",
    "    df = pd.concat([df, gfe.fit_transform(df)], axis=1)\n",
    "    class KNNFeatureExtractor:\n",
    "        def __init__(self, n_neighbors=5):\n",
    "            self.knn = KNeighborsClassifier(n_neighbors + 1)\n",
    "        def fit(self, X, y):\n",
    "            self.knn.fit(X, y)\n",
    "            self.y = y if isinstance(y, np.ndarray) else np.array(y)\n",
    "            return self\n",
    "        def transform(self, X, is_train_data):\n",
    "            distances, indexes = self.knn.kneighbors(X)\n",
    "            distances = distances[:, 1:] if is_train_data else distances[:, :-1]\n",
    "            indexes = indexes[:, 1:] if is_train_data else indexes[:, :-1]\n",
    "            labels = self.y[indexes]\n",
    "            score_columns = [f\"knn_score_class{c:02d}\" for c in range(N_CLASSES)]\n",
    "            df_knn = pd.DataFrame(\n",
    "                [np.bincount(labels_, distances_, N_CLASSES) for labels_, distances_ in zip(labels, 1.0 / distances)],\n",
    "                columns=score_columns\n",
    "            )\n",
    "            df_knn[\"max_knn_scores\"] = df_knn.max(1)\n",
    "            for col in score_columns:\n",
    "                df_knn[f\"sub_max_knn_scores_{col}\"] = df_knn[\"max_knn_scores\"] - df_knn[col]\n",
    "            for i, col1 in enumerate(score_columns):\n",
    "                for j, col2 in enumerate(score_columns[i+1:], i+1):\n",
    "                    if {i, j} & {8, 10}:\n",
    "                        df_knn[f\"sub_{col1}_{col2}\"] = df_knn[col1] - df_knn[col2]\n",
    "            df_knn[\"sum_knn_scores\"] = df_knn.sum(1)\n",
    "            return df_knn\n",
    "    # feature scaling\n",
    "    df[\"log_tempo\"] = np.log(df[\"tempo\"])\n",
    "    for col in [\n",
    "        'popularity', 'duration_ms', 'acousticness',\n",
    "        'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "        'speechiness', 'instrumentalness', 'log_tempo', 'num_nans',\n",
    "    ]:\n",
    "        df[\"standardscaled_\" + col] = StandardScaler().fit_transform(df[[col]])[:, 0]\n",
    "    df_train, df_test = split_train_test(df)\n",
    "    target = df_train[\"genre\"]\n",
    "    \n",
    "    \n",
    "    # train\n",
    "    \n",
    "    N_SPLITS = 15\n",
    "    SEED_SKF = 42\n",
    "    np.random.seed(42)\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\n",
    "    oof = np.zeros((len(df_train), N_CLASSES))\n",
    "    predictions = np.zeros((len(df_test), N_CLASSES))\n",
    "    df_feature_importance = pd.DataFrame()\n",
    "    features_numerical = [\n",
    "        'popularity', 'duration_ms', 'acousticness',\n",
    "        'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "        'speechiness', 'instrumentalness', 'tempo',\n",
    "        'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "        'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "        'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "        'region_S', 'region_T', 'region_unknown', 'countenc_region',\n",
    "        'num_nans',\n",
    "        'agg_zscore_popularity_grpby_region',\n",
    "        'agg_zscore_duration_ms_grpby_region',\n",
    "        'agg_zscore_acousticness_grpby_region',\n",
    "        'agg_zscore_positiveness_grpby_region',\n",
    "        'agg_zscore_danceability_grpby_region',\n",
    "        'agg_zscore_loudness_grpby_region', 'agg_zscore_energy_grpby_region',\n",
    "        'agg_zscore_liveness_grpby_region',\n",
    "        'agg_zscore_speechiness_grpby_region',\n",
    "        'agg_zscore_instrumentalness_grpby_region',\n",
    "        'agg_zscore_log_tempo_grpby_region',\n",
    "        'knn_score_class00', 'knn_score_class01',\n",
    "        'knn_score_class02', 'knn_score_class03', 'knn_score_class04',\n",
    "        'knn_score_class05', 'knn_score_class06', 'knn_score_class07',\n",
    "        'knn_score_class08', 'knn_score_class09', 'knn_score_class10',\n",
    "        'max_knn_scores',\n",
    "        'sub_max_knn_scores_knn_score_class00',\n",
    "        'sub_max_knn_scores_knn_score_class01',\n",
    "        'sub_max_knn_scores_knn_score_class02',\n",
    "        'sub_max_knn_scores_knn_score_class03',\n",
    "        'sub_max_knn_scores_knn_score_class04',\n",
    "        'sub_max_knn_scores_knn_score_class05',\n",
    "        'sub_max_knn_scores_knn_score_class06',\n",
    "        'sub_max_knn_scores_knn_score_class07',\n",
    "        'sub_max_knn_scores_knn_score_class08',\n",
    "        'sub_max_knn_scores_knn_score_class09',\n",
    "        'sub_max_knn_scores_knn_score_class10',\n",
    "        'sub_knn_score_class00_knn_score_class08',\n",
    "        'sub_knn_score_class00_knn_score_class10',\n",
    "        'sub_knn_score_class01_knn_score_class08',\n",
    "        'sub_knn_score_class01_knn_score_class10',\n",
    "        'sub_knn_score_class02_knn_score_class08',\n",
    "        'sub_knn_score_class02_knn_score_class10',\n",
    "        'sub_knn_score_class03_knn_score_class08',\n",
    "        'sub_knn_score_class03_knn_score_class10',\n",
    "        'sub_knn_score_class04_knn_score_class08',\n",
    "        'sub_knn_score_class04_knn_score_class10',\n",
    "        'sub_knn_score_class05_knn_score_class08',\n",
    "        'sub_knn_score_class05_knn_score_class10',\n",
    "        'sub_knn_score_class06_knn_score_class08',\n",
    "        'sub_knn_score_class06_knn_score_class10',\n",
    "        'sub_knn_score_class07_knn_score_class08',\n",
    "        'sub_knn_score_class07_knn_score_class10',\n",
    "        'sub_knn_score_class08_knn_score_class09',\n",
    "        'sub_knn_score_class08_knn_score_class10',\n",
    "        'sub_knn_score_class09_knn_score_class10',\n",
    "        'sum_knn_scores'\n",
    "    ]\n",
    "    features_categorical = [\"labelenc_region\"]\n",
    "    features = features_numerical + features_categorical\n",
    "    for fold_, (indexes_trn, indexes_val) in enumerate(skf.split(df_train.values, target.values)):\n",
    "        print(f\"------------------------------ fold {fold_} ------------------------------\")\n",
    "        df_trn = df_train.loc[indexes_trn].reset_index(drop=True)\n",
    "        df_val = df_train.loc[indexes_val].reset_index(drop=True)\n",
    "        target_trn = target.loc[indexes_trn].reset_index(drop=True)\n",
    "        target_val = target.loc[indexes_val].reset_index(drop=True)\n",
    "        # make knn features\n",
    "        X = df_trn[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        knn_feature_extractor = KNNFeatureExtractor(knn_n_neighbors).fit(X, target_trn)\n",
    "        df_trn = pd.concat([df_trn, knn_feature_extractor.transform(X, is_train_data=True)], axis=1)\n",
    "        X = df_val[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        df_val = pd.concat([df_val, knn_feature_extractor.transform(X, is_train_data=False)], axis=1)\n",
    "        X = df_test[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        df_test_knn_features = knn_feature_extractor.transform(X, is_train_data=False)\n",
    "        for col in df_test_knn_features.columns:\n",
    "            df_test[col] = df_test_knn_features[col]\n",
    "        lgb_train = lgb.Dataset(\n",
    "            df_trn.loc[:, features],\n",
    "            label=target_trn,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "        )\n",
    "        lgb_valid = lgb.Dataset(\n",
    "            df_val.loc[:, features],\n",
    "            label=target_val,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "        )\n",
    "        lgb_params[\"learning_rate\"] = learning_rate + np.random.random() * 0.001  # おまじない\n",
    "        num_round = 999999999\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            lgb_train, \n",
    "            num_round, \n",
    "            valid_sets=[lgb_train, lgb_valid], \n",
    "            verbose_eval=300,\n",
    "            early_stopping_rounds=300 if num_round >= 1e8 else None,\n",
    "            fobj=None,\n",
    "            #feval=lgb_metric,\n",
    "        )\n",
    "        # cv\n",
    "        prediction_round = model.best_iteration+150 if num_round >= 1e8 else num_round  # おまじない\n",
    "        oof[indexes_val] = model.predict(df_val[features], num_iteration=prediction_round)\n",
    "        # feature importance\n",
    "        df_fold_importance = pd.DataFrame()\n",
    "        df_fold_importance[\"feature\"] = features\n",
    "        df_fold_importance[\"importance\"] = model.feature_importance()\n",
    "        df_fold_importance[\"fold\"] = fold_\n",
    "        df_feature_importance = pd.concat([df_feature_importance, df_fold_importance], axis=0)\n",
    "        # prediction for test data\n",
    "        predictions += model.predict(df_test[features], num_iteration=prediction_round) / N_SPLITS\n",
    "        print()\n",
    "    \n",
    "    score = f1_score(target, oof.argmax(1), average=\"macro\")\n",
    "    print(\"CV score (not reliable!)\")\n",
    "    print(f\"  f1: {score:8.5f}\")\n",
    "    print()\n",
    "    print(classification_report(target, oof.argmax(1)))\n",
    "    \n",
    "    \n",
    "    df_test[\"prediction\"] = predictions.argmax(1)\n",
    "    df_test[\"confidence\"] = predictions.max(1)\n",
    "    df_test[\"genre\"] = np.where(predictions.max(1) > pseudo_labeling_threshold, predictions.argmax(1), -100)\n",
    "    df = merge_train_test(df_train, df_test)\n",
    "    df_main[\"genre\"] = df_main[\"index\"].map(dict(df[[\"index\", \"genre\"]].values))\n",
    "    print((df_test[\"confidence\"] > pseudo_labeling_threshold).sum(), f\"rows were filled. (confidence>{pseudo_labeling_threshold})\")\n",
    "    print(\"filled test labels:\", np.bincount(df_test[df_test[\"genre\"]!=-100][\"genre\"]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2bba7e-f254-4adc-9171-9dc9eea6dfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
