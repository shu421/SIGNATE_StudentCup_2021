{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a8dc6-0820-4942-b2bb-f9c6d86295f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 300\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('../modules/')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec044a-6b91-4a1b-8875-39d9b4e74c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '/Users/shugo/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421'\n",
    "\n",
    "# make config\n",
    "INPUT = os.path.join(ROOT, 'input') # パスの結合\n",
    "OUTPUT = os.path.join(ROOT, 'output')\n",
    "SUBMISSION = os.path.join(ROOT, 'submission')\n",
    "\n",
    "EXP_NAME = 'main'\n",
    "EXP = os.path.join(OUTPUT, EXP_NAME)\n",
    "PREDS = os.path.join(EXP, 'preds')\n",
    "TRAINED = os.path.join(EXP, 'trained')\n",
    "FEATURE = os.path.join(EXP, 'feature')\n",
    "REPORTS = os.path.join(EXP, 'reports')\n",
    "\n",
    "# make experiments environment\n",
    "dirs = [\n",
    "        OUTPUT,\n",
    "        SUBMISSION,\n",
    "        FEATURE,\n",
    "        EXP,\n",
    "        PREDS,\n",
    "        TRAINED,\n",
    "        REPORTS\n",
    "        ]\n",
    "\n",
    "# パスが通ってなかったら、新しいパスを通す\n",
    "for v in dirs:\n",
    "    if not os.path.isdir(v):\n",
    "        print(f'making {v}')\n",
    "        os.makedirs(v, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795a9a6-62ca-4b77-9b02-f8fc69ff8907",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a6013-5749-4542-a115-0785ed306a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(INPUT+'/train.csv')\n",
    "test = pd.read_csv(INPUT+'/test.csv')\n",
    "sample_sub = pd.read_csv(INPUT+'/sample_submit.csv')\n",
    "genre_labels = pd.read_csv(INPUT+'/genre_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a16c47-cf4c-4e45-93de-29dcf2e0cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load用のクラス\n",
    "class Util:\n",
    "    @classmethod\n",
    "    def dump(cls, value, path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        joblib.dump(value, path, compress=True) # 並列処理\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return joblib.load(path)\n",
    "    \n",
    "# log用のクラス\n",
    "class Logger:\n",
    "    def __init__(self, path):\n",
    "        self.general_logger = logging.getLogger(path) # loggerを設定\n",
    "        stream_handler = logging.StreamHandler() # loggerからlogRecordを渡される\n",
    "        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n",
    "        if len(self.general_logger.handlers) == 0:\n",
    "            self.general_logger.addHandler(stream_handler)\n",
    "            self.general_logger.addHandler(file_general_handler)\n",
    "            self.general_logger.setLevel(logging.INFO)\n",
    "            \n",
    "    def info(self, message):\n",
    "        # display time\n",
    "        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n",
    "    \n",
    "    @staticmethod\n",
    "    def now_string():\n",
    "        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "# loggerの設定\n",
    "logger = Logger(REPORTS) # REPORTフォルダにlog結果を保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7947f00-b865-4866-8724-c638cf931b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 11\n",
    "\n",
    "# testのジャンルを-100として結合\n",
    "def merge_train_test(train, test):\n",
    "    if 'genre' not in test.columns.tolist():\n",
    "        test['genre'] = -100\n",
    "    res = pd.concat([train,test])\n",
    "    res.reset_index(inplace=True, drop = True)\n",
    "    return res\n",
    "\n",
    "def split_train_test(input_df):\n",
    "    train = input_df[input_df['genre'] != -100]\n",
    "    test = input_df[input_df['genre'] == -100]\n",
    "    train.reset_index(inplace=True, drop=True)\n",
    "    test.reset_index(inplace=True, drop =True)\n",
    "    return train, test\n",
    "\n",
    "df = merge_train_test(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67451aa5-4044-4bf7-a14f-efe1eedb4c4d",
   "metadata": {},
   "source": [
    "# Feature Enginnering\n",
    "  ## class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc88978-9a44-4b91-a665-52543c39f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regionについてgroupbyし、その出現頻度をcountする\n",
    "class CountEncoder:\n",
    "    def fit(self, series):\n",
    "        self.counts = series.groupby(series).count()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, series):\n",
    "        return series.map(self.counts).fillna(0)\n",
    "    \n",
    "    def fit_transform(self, series):\n",
    "        return self.fit(series).transform(series)\n",
    "    \n",
    "\n",
    "#　標準偏差とz得点\n",
    "class GroupFeatureExtractor:\n",
    "    EX_TRANS_METHODS = ['deviation', 'zscore']\n",
    "    \n",
    "    def __init__(self, group_key, group_values, agg_methods):\n",
    "        self.group_key = group_key\n",
    "        self.group_values = group_values\n",
    "        \n",
    "        self.ex_trans_methods = [m for m in agg_methods if m in self.EX_TRANS_METHODS]\n",
    "        self.agg_methods = [m for m in agg_methods if m not in self.ex_trans_methods]\n",
    "        self.df_agg = None\n",
    "\n",
    "    def fit(self, df_train, y=None):\n",
    "        if not self.agg_methods:\n",
    "            return\n",
    "        dfs = []\n",
    "        for agg_method in self.agg_methods:\n",
    "            if callable(agg_methods): # 呼び出し可能か判定\n",
    "                agg_method_name = agg_method.__name__ # ?\n",
    "            else:\n",
    "                agg_method_name = agg_method\n",
    "            df_agg = (df_train[[self.group_key] + self.group_values].groupby(self.group_key).agg(agg_method))\n",
    "            df_agg.columns = self._get_columns_names(agg_method_name)\n",
    "            dfs.append(df_agg)\n",
    "        self.df_agg = pd.concat(dfs, axis=1).reset_index()\n",
    "        \n",
    "    def transform(self, df_eval):\n",
    "        key = self.group_key\n",
    "        if self.agg_methods:\n",
    "            df_features = pd.merge(df_eval[[self.group_key]], self.df_agg, on=self.group_key, how='left')\n",
    "        else:\n",
    "            df_features = df_eval[[self.group_key]].copy()\n",
    "        if self.ex_trans_methods:\n",
    "            if 'deviation' in self.ex_trans_methods:\n",
    "                df_features[self._get_column_names('deviation')] = df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform('mean')\n",
    "            if 'zscore' in self.ex_trans_methods:\n",
    "                df_features[self._get_column_names('zscore')] = (df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform('mean')) \\\n",
    "                                                                                                            / (df_eval[[key]+self.group_values].groupby(key).transform('std') + 1e-8)\n",
    "            df_features.drop(self.group_key, axis=1, inplace = True)\n",
    "            return df_features\n",
    "        \n",
    "    def _get_column_names(self, method):\n",
    "        return [f'agg_{method}_{col}_grpby_{self.group_key}' for col in self.group_values]\n",
    "        \n",
    "    def fit_transform(self, df_train, y=None):\n",
    "        self.fit(df_train, y=y)\n",
    "        return self.transform(df_train)\n",
    "\n",
    "\n",
    "# K近傍法特徴量\n",
    "class KNNFeatureExtractor:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.knn = KNeighborsClassifier(n_neighbors + 1)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.knn.fit(X, y)\n",
    "        self.y = y if isinstance(y, np.ndarray) else np.array(y) # 型判定の組み込み関数isinstanceはboolを返す。np.arrayのyを返す\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, is_train_data):\n",
    "        distances, indexes = self.knn.kneighbors(X) # ポイントXから最も近いポイントまでの距離と、そのインデックスを返す\n",
    "        \n",
    "        # train, testデータを判定\n",
    "        distances = distances[:, 1:] if is_train_data else distances[:, :-1]\n",
    "        indexes = indexes[:, 1:] if is_train_data else indexes[:, :-1]\n",
    "        labels = self.y[indexes]\n",
    "        score_columns = [f\"knn_score_class{c:02d}\" for c in range(N_CLASSES)]\n",
    "        df_knn = pd.DataFrame(\n",
    "                [np.bincount(labels_, distances_, N_CLASSES) for labels_, distances_ in zip(labels, 1.0 / distances)], # bincount : 要素の個数を返す\n",
    "                columns=score_columns\n",
    "        )\n",
    "        \n",
    "        # 最大スコア\n",
    "        df_knn['max_knn_scores'] = df_knn.max(axis=1)\n",
    "        \n",
    "        # 最大スコアとの差。0は最大スコアを表す\n",
    "        for col in score_columns:\n",
    "            df_knn[f'sub_max_knn_scores_{col}'] = df_knn['max_knn_scores'] - df_knn[col]\n",
    "        \n",
    "        # 最大スコアとの比。1は最大スコアを表す\n",
    "        for col in score_columns:\n",
    "            df_knn[f'div_max_knn_scores_{col}'] = df_knn[col] / df_knn['max_knn_scores']\n",
    "        \n",
    "        # それぞれのスコア同士の差\n",
    "        for i, col1 in enumerate(score_columns):\n",
    "            for j, col2 in enumerate(score_columns[i+1:], i+1): # 全パターンを網羅できる\n",
    "                df_knn[f'sub_{col1}_{col2}'] = df_knn[col1] - df_knn[col2]\n",
    "        \n",
    "        # knnスコアの合計\n",
    "        df_knn['sum_knn_scores'] = df_knn.sum(1)\n",
    "        \n",
    "        return df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8df86-a975-4557-bf6a-3fb7e0c9beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre_region_grpby = train.groupby('region')['acousticness'].mean()\n",
    "display(df_genre_region_grpby.sort_values(ascending=True))\n",
    "#df_genre_region_grpby.plot.hist()\n",
    "import seaborn as sns\n",
    "sns.histplot(x=df_genre_region_grpby.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d91db1-6268-4fdf-b351-9dab5353d025",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f14b5b05-97ec-414a-84c4-251ea679e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train)\n",
    "def get_target(input_df):\n",
    "    global n_train\n",
    "    if 'genre' in input_df.columns:\n",
    "        output_df = input_df['genre'][:n_train]\n",
    "        return output_df\n",
    "\n",
    "def get_numerical_features(input_df):\n",
    "    # そのままの数値特徴\n",
    "    cols = ['popularity',\n",
    "            'duration_ms',\n",
    "            'acousticness',\n",
    "            'positiveness',\n",
    "            'danceability',\n",
    "            'loudness',\n",
    "            'energy',\n",
    "            'liveness',\n",
    "            'speechiness',\n",
    "            'instrumentalness']\n",
    "    output_df = input_df[cols].copy()\n",
    "    return output_df\n",
    "\n",
    "def get_genre_name(input_df):\n",
    "    output_df = pd.DataFrame()\n",
    "    output_df['genre_name'] = input_df['genre'].map(dict(genre_labels[['labels', 'genre']].values)).copy()\n",
    "    return output_df\n",
    "   \n",
    "def get_tempo_features(input_df):\n",
    "    _df = input_df['tempo'].str.split('-').apply(pd.Series).astype(float)\n",
    "    _df.columns = ['tempo_low', 'tempo_high']\n",
    "    output_df = _df.copy()\n",
    "    output_df['mean_tempo'] = (_df['tempo_high'] + _df['tempo_low'])/2\n",
    "    output_df['diff_tempo'] = _df['tempo_high'] - _df['tempo_low']\n",
    "    output_df['var_tempo'] = _df.var(axis=1) # tempo_highとtempo_lowの分散をとる\n",
    "    output_df['sum_tempo'] = _df.sum(axis=1)\n",
    "    output_df['log_tempo'] = np.log(output_df['mean_tempo'])\n",
    "    return output_df\n",
    "\n",
    "def get_region_onehot(input_df):\n",
    "    # regionをone-hotし、unknownをregion_unknownとする\n",
    "    output_df = pd.get_dummies(input_df['region']).rename(columns={'unknown' : 'region_unknown'})\n",
    "    return output_df\n",
    "\n",
    "def get_num_nans(input_df):\n",
    "    # 曲ごとのnanの数\n",
    "    input_df['num_nans'] = 0\n",
    "    for col in [\n",
    "        'acousticness',\n",
    "        'positiveness',\n",
    "        'danceability',\n",
    "        'energy',\n",
    "        'liveness',\n",
    "        'speechiness',\n",
    "        'instrumentalness'\n",
    "    ]:\n",
    "        input_df['num_nans'] += input_df[col].isna()\n",
    "        output_df = input_df['num_nans'].apply(pd.Series)\n",
    "        output_df.columns = ['num_nans']\n",
    "        return output_df\n",
    "\n",
    "def get_ce_features(input_df):\n",
    "    columns_count_enc = ['region']\n",
    "    output_df = pd.DataFrame()\n",
    "    for col in columns_count_enc:\n",
    "        output_df['countenc_' + col] = CountEncoder().fit_transform(input_df[col])\n",
    "        output_df.loc[input_df[col].isna().values, 'countenc_' + col]= np.nan\n",
    "    return output_df\n",
    "    \n",
    "def get_le_features(input_df):\n",
    "    columns_count_enc = ['region']\n",
    "    output_df = pd.DataFrame()\n",
    "    for col in columns_count_enc:\n",
    "        output_df['labelenc_' + col] = LabelEncoder().fit_transform(input_df[col])\n",
    "        output_df.loc[input_df[col].isna().values, 'labelenc_' + col]= np.nan\n",
    "    return output_df\n",
    "\n",
    "def get_standardscaled_features(input_df):\n",
    "    output_df = pd.DataFrame()\n",
    "    _input_df = pd.concat([get_numerical_features(input_df),\n",
    "                           get_tempo_features(input_df),\n",
    "                           get_num_nans(input_df)], axis=1)\n",
    "    for col in [\n",
    "        'popularity', 'duration_ms', 'acousticness',\n",
    "        'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "        'speechiness', 'instrumentalness', 'log_tempo', 'num_nans'\n",
    "    ]:\n",
    "        output_df['standardscaled_' + col] = StandardScaler().fit_transform(_input_df[[col]])[:, 0]\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# regionをキーにした集約統計量\n",
    "def get_agg_region_features(input_df):\n",
    "    _input_df = pd.concat([get_numerical_features(input_df),\n",
    "                          get_tempo_features(input_df),\n",
    "                          input_df[['region']]], axis=1)\n",
    "    group_key = 'region'\n",
    "    group_values = ['popularity',\n",
    "                    'duration_ms',\n",
    "                    'acousticness',\n",
    "                    'positiveness',\n",
    "                    'danceability',\n",
    "                    'loudness',\n",
    "                    'energy',\n",
    "                    'liveness',\n",
    "                    'speechiness',\n",
    "                    'instrumentalness', \n",
    "                    'tempo_low', \n",
    "                    'tempo_high',\n",
    "                    'log_tempo']\n",
    "    agg_methods = ['deviation', 'zscore']\n",
    "    gfe = GroupFeatureExtractor(\n",
    "        group_key=group_key,\n",
    "        group_values=group_values,\n",
    "        agg_methods=agg_methods)\n",
    "    output_df = gfe.fit_transform(_input_df)\n",
    "    return output_df\n",
    "\n",
    "def get_binning_features(input_df, target='acousticness', num_bins=3):#, target='acousticness', num_bins=11):\n",
    "    binned = pd.cut(input_df[target], num_bins, labels=False)\n",
    "    output_df = pd.DataFrame({f'binned_{target}' : binned})\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "32967568-3b00-4099-a2d3-08da24027ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上で作った関数を実行し、train, testそれぞれで処理を行う\n",
    "\n",
    "def preprocess(input_df, funcs, task='train'):\n",
    "    df_lst = []\n",
    "    for func in funcs:\n",
    "        file_name = os.path.join(FEATURE, f'{task}_{func.__name__}.pkl')\n",
    "        # パスが通っていたら、その中身を返す\n",
    "        if os.path.isfile(file_name):\n",
    "            _df = Util.load(file_name)\n",
    "        # 通ってなかったら\n",
    "        else:\n",
    "            _df = func(input_df)\n",
    "            Util.dump(_df, file_name)\n",
    "        df_lst.append(_df)\n",
    "    output_df = pd.concat(df_lst, axis=1)\n",
    "    return output_df\n",
    "\n",
    "def get_train_data(train, test):\n",
    "    # each_funcs : trainのみを対象とした処理\n",
    "    each_funcs = [get_numerical_features,\n",
    "                  get_tempo_features,\n",
    "                  get_num_nans,\n",
    "                  get_ce_features,\n",
    "                  get_le_features,\n",
    "                  get_standardscaled_features,\n",
    "                  get_agg_region_features,\n",
    "                  get_region_onehot,\n",
    "                  #get_binning_features\n",
    "                 ]\n",
    "    train_out = preprocess(train, each_funcs, task='train') # each_funcsによる前処理\n",
    "    \n",
    "    # whole_funcs : train+testの全体集合を対象とした処理\n",
    "    #whole_funcs = []\n",
    "    #whole_df = pd.concat([train, test], axis=0).reset_index(drop=True) # whole_funcs用のデータ\n",
    "    #whole_out = preprocess(whole_df, whole_funcs, task='whole') # whole_funcsによる前処理\n",
    "    #train_x = pd.concat([train_out,\n",
    "                        #whole_out.iloc[:len(train)]], axis=1)\n",
    "    train_x = train_out\n",
    "    return train_x\n",
    "\n",
    "def get_test_data(train, test):\n",
    "    # each_funcs : testのみを対象とした処理\n",
    "    each_funcs = [get_numerical_features,\n",
    "                  get_tempo_features,\n",
    "                  get_num_nans,\n",
    "                  get_ce_features,\n",
    "                  get_le_features,\n",
    "                  get_standardscaled_features,\n",
    "                  get_agg_region_features,\n",
    "                  get_region_onehot,\n",
    "                  #get_binning_features\n",
    "                 ]\n",
    "    test_out = preprocess(test, each_funcs, task='test')\n",
    "    \n",
    "    # whole_funcs : train+testの全体集合を対象とした処理\n",
    "    #whole_funcs = []\n",
    "    #whole_df = pd.concat([train, test]).reset_index(drop=True)\n",
    "    #whole_out = preprocess(whole_df, whole_funcs, task='whole') # whole_funcsによる前処理\n",
    "    #test_x = pd.concat([test_out,\n",
    "                       #whole_out.iloc[len(train):].reset_index(drop=True)], axis=1)\n",
    "    test_x = test_out\n",
    "    return test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "047403e6-cfce-49ea-9635-a5cf62c58409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (4046, 79)\n",
      "target (4046,)\n",
      "test_x (4046, 79)\n"
     ]
    }
   ],
   "source": [
    "# get features, 前処理の実行部分\n",
    "train_x = get_train_data(train, test)\n",
    "test_x = get_test_data(train, test)\n",
    "test_x['region_M'] = 0\n",
    "target = train['genre']\n",
    "print('train_x', train_x.shape)\n",
    "print('target', target.shape)\n",
    "print('test_x', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed9395-22c7-4761-969f-48166834a5e6",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3968536e-f8c5-4c05-bf54-f183567bb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0a0d7fd4-b8d9-4ae7-a08d-094b45c13305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7c1bcb74-89d5-4588-81b7-c07584c27083",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": N_CLASSES,\n",
    "    #\"metric\": \"None\",\n",
    "    'metric': 'multi_logloss',\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"num_leaves\": 3,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "    #\"colsample_bytree\": 1.0,\n",
    "    #\"feature_fraction\": 1.0,\n",
    "    #\"bagging_freq\": 0,\n",
    "    #\"bagging_fraction\": 1.0,\n",
    "    \"verbosity\": 0,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "knn_n_neighbors = 6\n",
    "\n",
    "\n",
    "# parameters - knn feature weights\n",
    "\n",
    "knn_features = [\n",
    "   'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "   'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "   'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "   'region_S', 'region_T', 'region_unknown',\n",
    "   'standardscaled_popularity', 'standardscaled_duration_ms',\n",
    "   'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "   'standardscaled_danceability', 'standardscaled_loudness',\n",
    "   'standardscaled_energy', 'standardscaled_liveness',\n",
    "   'standardscaled_speechiness', 'standardscaled_instrumentalness',\n",
    "   'standardscaled_log_tempo', 'standardscaled_num_nans'\n",
    "]\n",
    "\n",
    "\n",
    "dict_feature_weights = {}\n",
    "\n",
    "for col in [\n",
    "    'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "    'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "    'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "    'region_S', 'region_T', 'region_unknown'\n",
    "]:\n",
    "    dict_feature_weights[col] = 100.0\n",
    "\n",
    "for col in [\n",
    "    'standardscaled_duration_ms',\n",
    "    'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "    'standardscaled_danceability', 'standardscaled_loudness',\n",
    "    'standardscaled_energy', 'standardscaled_liveness',\n",
    "    'standardscaled_speechiness', 'standardscaled_instrumentalness'\n",
    "]:\n",
    "    dict_feature_weights[col] = 1.0\n",
    "\n",
    "dict_feature_weights[\"standardscaled_popularity\"] = 8.0\n",
    "dict_feature_weights[\"standardscaled_log_tempo\"] = 0.001\n",
    "dict_feature_weights[\"standardscaled_num_nans\"] = 100.0\n",
    "\n",
    "knn_feature_weights = np.array([dict_feature_weights[col] for col in knn_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e029ee82-c533-4ca1-b966-c666a57e6c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- fold0 --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-09 17:12:03,383]\u001b[0m A new study created in memory with name: no-name-74a10dfc-5937-4e3d-b969-0930ff6e308b\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/Users/shugo/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/Users/shugo/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/shugo/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Training until validation scores don't improve for 300 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-161a74a495c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[0;34m>=\u001b[0m\u001b[0;36m1e8\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m#fobj=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m#feval=lgb_metric,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/__init__.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mauto_booster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightGBMTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mauto_booster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_booster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_train_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_feature_fraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_num_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_bagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mtune_feature_fraction\u001b[0;34m(self, n_trials)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_values\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tune_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature_fraction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtune_num_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m_tune_params\u001b[0;34m(self, target_param_names, n_trials, sampler, step_name)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                 \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optuna_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m             )\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_sets\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_valid_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_booster_best_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SIGNATE/SIGNATE_StudentCup2021/shu421/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2643\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2645\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2646\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_SPLITS = 15\n",
    "SEED_SKF = 71\n",
    "np.random.seed(71)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\n",
    "oof = np.zeros((len(train), N_CLASSES))\n",
    "predictions = np.zeros((len(test), N_CLASSES))\n",
    "df_feature_importance = pd.DataFrame()\n",
    "\n",
    "features_numerical = [\n",
    "    'popularity', 'duration_ms', 'acousticness',\n",
    "    'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "    'speechiness', 'instrumentalness',\n",
    "    'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "    'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "    'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "    'region_S', 'region_T', 'region_unknown', 'countenc_region',\n",
    "    'num_nans',\n",
    "    'agg_zscore_popularity_grpby_region',\n",
    "    'agg_zscore_duration_ms_grpby_region',\n",
    "    'agg_zscore_acousticness_grpby_region',\n",
    "    'agg_zscore_positiveness_grpby_region',\n",
    "    'agg_zscore_danceability_grpby_region',\n",
    "    'agg_zscore_loudness_grpby_region', 'agg_zscore_energy_grpby_region',\n",
    "    'agg_zscore_liveness_grpby_region',\n",
    "    'agg_zscore_speechiness_grpby_region',\n",
    "    'agg_zscore_instrumentalness_grpby_region',\n",
    "    'agg_zscore_log_tempo_grpby_region',\n",
    "    'knn_score_class00', 'knn_score_class01',\n",
    "    'knn_score_class02', 'knn_score_class03', 'knn_score_class04',\n",
    "    'knn_score_class05', 'knn_score_class06', 'knn_score_class07',\n",
    "    'knn_score_class08', 'knn_score_class09', 'knn_score_class10',\n",
    "    'max_knn_scores',\n",
    "    'div_max_knn_scores_knn_score_class00',\n",
    "    'div_max_knn_scores_knn_score_class01',\n",
    "    'div_max_knn_scores_knn_score_class02',\n",
    "    'div_max_knn_scores_knn_score_class03',\n",
    "    'div_max_knn_scores_knn_score_class04',\n",
    "    'div_max_knn_scores_knn_score_class05',\n",
    "    'div_max_knn_scores_knn_score_class06',\n",
    "    'div_max_knn_scores_knn_score_class07',\n",
    "    'div_max_knn_scores_knn_score_class08',\n",
    "    'div_max_knn_scores_knn_score_class09',\n",
    "    'div_max_knn_scores_knn_score_class10',\n",
    "    'sub_max_knn_scores_knn_score_class00',\n",
    "    'sub_max_knn_scores_knn_score_class01',\n",
    "    'sub_max_knn_scores_knn_score_class02',\n",
    "    'sub_max_knn_scores_knn_score_class03',\n",
    "    'sub_max_knn_scores_knn_score_class04',\n",
    "    'sub_max_knn_scores_knn_score_class05',\n",
    "    'sub_max_knn_scores_knn_score_class06',\n",
    "    'sub_max_knn_scores_knn_score_class07',\n",
    "    'sub_max_knn_scores_knn_score_class08',\n",
    "    'sub_max_knn_scores_knn_score_class09',\n",
    "    'sub_max_knn_scores_knn_score_class10',\n",
    "    'sum_knn_scores',\n",
    "    #'binned_acousticness'\n",
    "]\n",
    "sub_knn_score_n_m = []\n",
    "score_columns = [f\"knn_score_class{c:02d}\" for c in range(N_CLASSES)]\n",
    "for i, col1 in enumerate(score_columns):\n",
    "    for j, col2 in enumerate(score_columns[i+1:], i+1):\n",
    "        sub_knn_score_n_m.append(f'sub_{col1}_{col2}')\n",
    "features_numerical += sub_knn_score_n_m        \n",
    "\n",
    "\n",
    "features_categorical = ['labelenc_region']\n",
    "features = features_numerical + features_categorical\n",
    "\n",
    "for fold_, (indexes_trn, indexes_val) in enumerate(skf.split(train_x.values, target.values)):\n",
    "    print('-'*50, 'fold{}'.format(fold_), '-'*50)\n",
    "\n",
    "    df_trn = train_x.loc[indexes_trn].reset_index(drop=True) # dfになってる\n",
    "    df_val = train_x.loc[indexes_val].reset_index(drop=True)\n",
    "    target_trn = target.loc[indexes_trn].reset_index(drop=True)\n",
    "    target_val = target.loc[indexes_val].reset_index(drop=True)\n",
    "\n",
    "    # make knn features\n",
    "    X = df_trn[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "\n",
    "    knn_feature_extractor = KNNFeatureExtractor(knn_n_neighbors).fit(X, target_trn)\n",
    "\n",
    "    df_trn = pd.concat([df_trn, knn_feature_extractor.transform(X, is_train_data=True)], axis=1)\n",
    "\n",
    "    X = df_val[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "    df_val = pd.concat([df_val, knn_feature_extractor.transform(X, is_train_data=False)], axis=1)\n",
    "\n",
    "    X = test_x[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "    df_test_knn_features = knn_feature_extractor.transform(X, is_train_data=False)\n",
    "\n",
    "    for col in df_test_knn_features.columns:\n",
    "        test_x[col] = df_test_knn_features[col]\n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "            df_trn.loc[:, features],\n",
    "            label=target_trn,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "    )\n",
    "    lgb_valid = lgb.Dataset(\n",
    "            df_val.loc[:, features],\n",
    "            label=target_val,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "    )\n",
    "\n",
    "    lgb_params['learning_rate'] = learning_rate + np.random.random() * 0.001 # おまじない\n",
    "    num_round = 999999999\n",
    "    model = lgb.train(\n",
    "            lgb_params,\n",
    "            lgb_train,\n",
    "            num_round,\n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            verbose_eval=-1,\n",
    "            early_stopping_rounds=300 if num_round >=1e8 else None,\n",
    "            #fobj=None,\n",
    "            #feval=lgb_metric,\n",
    "    )\n",
    "\n",
    "    # cv\n",
    "    prediction_round = model.best_iteration+150 if num_round >= 1e8 else num_round # おまじない\n",
    "    oof[indexes_val] = model.predict(df_val[features], num_iteration=prediction_round)\n",
    "\n",
    "    # feature importance\n",
    "    df_fold_importance = pd.DataFrame()\n",
    "    df_fold_importance['feature'] = features\n",
    "    df_fold_importance['importance'] = model.feature_importance()\n",
    "    df_fold_importance['fold'] = fold_\n",
    "    df_feature_importance = pd.concat([df_feature_importance, df_fold_importance], axis=0)\n",
    "\n",
    "    # prediction for test data\n",
    "    predictions += model.predict(test_x[features], num_iteration=prediction_round) /N_SPLITS\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e3801-0010-41f3-9a1f-d59ac02417c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.loc[:, 'prediction'] = predictions.argmax(1)\n",
    "score = f1_score(target, oof.argmax(1), average='macro')\n",
    "print('CV score')\n",
    "print('f1 : {:8.5f}'.format(score))\n",
    "print()\n",
    "print(classification_report(target, oof.argmax(1)))\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(12, 16))\n",
    "sns.barplot(x='importance', y='feature', data=df_feature_importance.sort_values(by='importance', ascending=False))\n",
    "plt.title('fature importance')\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb01f3c-65b6-4eae-91d6-3d1f42346abd",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcd299-f599-4ca9-8729-1469f8793c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_sub['genre'] = predictions.argmax(axis=1)\n",
    "display(df_sample_sub)\n",
    "df_sample_sub.to_csv('../outputs/sub_0501.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
